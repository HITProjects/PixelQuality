{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b1141ce5a3ba3f5",
   "metadata": {},
   "source": [
    "# LocJND - Patch-level JND Regression (Train)\n",
    "\n",
    "**Goal.**\n",
    "Train a small CNN to predict human noticeability of compression artifacts at patch level.\n",
    "Target is a scalar `y ∈ [0,1]` where `y = 1 − α`. Higher = more noticeable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4978a3f9b6ab01f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T17:21:51.352947Z",
     "start_time": "2025-09-16T17:21:51.345706Z"
    }
   },
   "outputs": [],
   "source": [
    "# CELL 0 — Imports and Reproducibility\n",
    "# This cell sets up all required libraries and fixes random seeds\n",
    "# to ensure consistent results across runs.\n",
    "\n",
    "import os\n",
    "import random\n",
    "from pydoc import pipepager\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from skimage.data import data_dir\n",
    "from tensorboard.notebook import display\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# --- reproducibility helper ---\n",
    "def set_seed(seed: int = 2025):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True  # allow speedup on GPU\n",
    "\n",
    "set_seed(2025)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1255cd3aff362fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T17:21:51.465447Z",
     "start_time": "2025-09-16T17:21:51.459482Z"
    }
   },
   "outputs": [],
   "source": [
    "# CELL 1 — Configuration\n",
    "# Central place to define hyperparameters and paths.\n",
    "\n",
    "from types import SimpleNamespace\n",
    "from datetime import datetime\n",
    "\n",
    "cfg = SimpleNamespace(\n",
    "    # --- training ---\n",
    "    epochs = 40,                 # 60–80 recommended for 20x20\n",
    "    batch_size = 128,            # safe default for 20x20\n",
    "    lr_init = 1e-4,\n",
    "    weight_decay = 1e-4,\n",
    "    img_size = 20,\n",
    "    num_workers = 0,             # Jupyter-friendly\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    seed = 2025,\n",
    "    aug_dup = 2,                 # duplicate train set via augmentation\n",
    "\n",
    "    # --- data paths (relative to project root) ---\n",
    "    data_dir = Path.cwd().parent / \"dataset\",\n",
    ")\n",
    "\n",
    "# derived paths\n",
    "cfg.train_csv = cfg.data_dir / \"blends_train.csv\"\n",
    "cfg.val_csv   = cfg.data_dir / \"blends_val.csv\"\n",
    "cfg.test_csv  = cfg.data_dir / \"blends_test.csv\"\n",
    "cfg.orig_dir  = cfg.data_dir / \"orig_patches\"\n",
    "cfg.mixed_dir = cfg.data_dir / \"mixed_patches\"\n",
    "\n",
    "# --- logging / checkpoints ---\n",
    "cfg.run_id = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "cfg.checkpoints_dir = Path(\"checkpoints\")\n",
    "cfg.runs_dir = Path(\"runs\")\n",
    "\n",
    "# ensure dirs\n",
    "cfg.checkpoints_dir.mkdir(parents=True, exist_ok=True)\n",
    "cfg.runs_dir.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5018819f3a9c50a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T17:21:51.481942Z",
     "start_time": "2025-09-16T17:21:51.472003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Paths OK\n",
      "data_dir      : C:\\Users\\YehonatanR\\OneDrive\\Documents\\HIT Computer Science\\3rd\\PixelQuality\\PythonProject\\dataset\n",
      "orig/mixed    : C:\\Users\\YehonatanR\\OneDrive\\Documents\\HIT Computer Science\\3rd\\PixelQuality\\PythonProject\\dataset\\orig_patches | C:\\Users\\YehonatanR\\OneDrive\\Documents\\HIT Computer Science\\3rd\\PixelQuality\\PythonProject\\dataset\\mixed_patches\n",
      "train/val/test: blends_train.csv, blends_val.csv, blends_test.csv\n",
      "LocJND.json   : C:\\Users\\YehonatanR\\OneDrive\\Documents\\HIT Computer Science\\3rd\\PixelQuality\\LocJND\\LocJND.json\n",
      "push99        : {'use_heatmap_weighting': True, 'use_gradient_channels': True, 'use_tta': True, 'ensemble_seeds': [2025, 2026, 2027], 'lambda_rank': 0.2, 'lambda_pearson': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# CELL 2 — Paths & Sanity\n",
    "# Verifies dataset layout and sets advanced training toggles.\n",
    "\n",
    "from types import SimpleNamespace\n",
    "\n",
    "def _must_exist(p: Path, name: str):\n",
    "    if not Path(p).exists():\n",
    "        raise FileNotFoundError(f\"Missing {name}: {p}\")\n",
    "\n",
    "# verify required folders/files\n",
    "for p, n in [\n",
    "    (cfg.data_dir, \"data_dir\"),\n",
    "    (cfg.orig_dir, \"orig_patches\"),\n",
    "    (cfg.mixed_dir, \"mixed_patches\"),\n",
    "    (cfg.train_csv, \"blends_train.csv\"),\n",
    "    (cfg.val_csv,   \"blends_val.csv\"),\n",
    "    (cfg.test_csv,  \"blends_test.csv\"),\n",
    "]:\n",
    "    _must_exist(p, n)\n",
    "\n",
    "# optional: LocJND.json (used later for references/metadata)\n",
    "cfg.locjnd_json = Path.cwd().parent / \"data\" / \"LocJND.json\"\n",
    "_must_exist(cfg.locjnd_json, \"LocJND.json\")\n",
    "\n",
    "cfg.push99 = SimpleNamespace(\n",
    "    use_heatmap_weighting=True,   # weighted MSE by heatmap if available\n",
    "    use_gradient_channels=True,   # add Sobel |∇orig|, |∇mixed|, |∇delta|\n",
    "    use_tta=True,                 # test-time augmentation (id,hflip,vflip,hv)\n",
    "    ensemble_seeds=[2025, 2026, 2027],\n",
    "    lambda_rank=0.2,              # weight for ranking loss\n",
    "    lambda_pearson=0.1,           # weight for Pearson loss (1 - corr)\n",
    ")\n",
    "\n",
    "# enforce Jupyter-friendly settings\n",
    "cfg.num_workers = 0\n",
    "cfg.aug_dup = getattr(cfg, \"aug_dup\", 1)\n",
    "\n",
    "print(\"✔ Paths OK\")\n",
    "print(f\"data_dir      : {cfg.data_dir}\")\n",
    "print(f\"orig/mixed    : {cfg.orig_dir} | {cfg.mixed_dir}\")\n",
    "print(f\"train/val/test: {cfg.train_csv.name}, {cfg.val_csv.name}, {cfg.test_csv.name}\")\n",
    "print(f\"LocJND.json   : {cfg.locjnd_json}\")\n",
    "print(\"push99        :\", cfg.push99.__dict__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee8da007dfd41cb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T17:21:52.574546Z",
     "start_time": "2025-09-16T17:21:51.575528Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train | n=672 | target mean=0.5000 std=0.3416 min=0.0000 max=1.0000\n",
      "  val | n=336 | target mean=0.5000 std=0.3416 min=0.0000 max=1.0000\n",
      " test | n=336 | target mean=0.5000 std=0.3416 min=0.0000 max=1.0000\n",
      "✓ mixed_path existence check passed on first 300 rows.\n",
      "✓ mixed_path existence check passed on first 300 rows.\n",
      "✓ mixed_path existence check passed on first 300 rows.\n",
      "Leakage check by image_id: train∩val=0 | train∩test=0 | val∩test=0\n"
     ]
    }
   ],
   "source": [
    "# CELL 3 — Read Splits\n",
    "# Load train/val/test CSVs, normalize paths, and print quick stats.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "REQUIRED_COLS = {\"mixed_path\", \"target\"}\n",
    "\n",
    "def _load_split(csv_path: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(csv_path, low_memory=False)\n",
    "    missing = REQUIRED_COLS - set(df.columns)\n",
    "    if missing:\n",
    "        raise KeyError(f\"CSV {csv_path.name} missing columns: {sorted(missing)}\")\n",
    "\n",
    "    # normalize types\n",
    "    df[\"mixed_path\"] = df[\"mixed_path\"].astype(str)\n",
    "    df[\"target\"] = df[\"target\"].astype(\"float32\")\n",
    "\n",
    "    # resolve absolute paths for mixed patches\n",
    "    def _resolve_mixed(p: str) -> str:\n",
    "        pth = Path(p)\n",
    "        if pth.is_absolute() and pth.exists():\n",
    "            return str(pth)\n",
    "        # try relative to dataset root\n",
    "        cand = (cfg.data_dir / pth).resolve()\n",
    "        if cand.exists():\n",
    "            return str(cand)\n",
    "        # try relative to mixed_patches directory using full relative and then just filename\n",
    "        cand2 = (cfg.mixed_dir / pth).resolve()\n",
    "        if cand2.exists():\n",
    "            return str(cand2)\n",
    "        cand3 = (cfg.mixed_dir / pth.name).resolve()\n",
    "        if cand3.exists():\n",
    "            return str(cand3)\n",
    "        # last resort: keep as-is (dataset check will catch later)\n",
    "        return str(cand)\n",
    "\n",
    "    df[\"mixed_path\"] = df[\"mixed_path\"].map(_resolve_mixed)\n",
    "\n",
    "    # optional: ensure unique key if provided\n",
    "    if \"image_id\" in df.columns:\n",
    "        df[\"image_id\"] = df[\"image_id\"].astype(str)\n",
    "\n",
    "    return df\n",
    "\n",
    "def _quick_stats(name: str, df: pd.DataFrame):\n",
    "    n = len(df)\n",
    "    tgt = df[\"target\"].to_numpy()\n",
    "    print(f\"{name:>5} | n={n} | target mean={tgt.mean():.4f} std={tgt.std():.4f} \"\n",
    "          f\"min={tgt.min():.4f} max={tgt.max():.4f}\")\n",
    "\n",
    "def _check_files_exist(df: pd.DataFrame, col: str = \"mixed_path\", limit: int = 300):\n",
    "    # Lightweight existence check\n",
    "    sample = df[col].head(limit).tolist()\n",
    "    missing = [p for p in sample if not Path(p).exists()]\n",
    "    if missing:\n",
    "        raise FileNotFoundError(f\"{len(missing)} missing files in first {len(sample)} rows (showing 3): {missing[:3]}\")\n",
    "    print(f\"✓ {col} existence check passed on first {len(sample)} rows.\")\n",
    "\n",
    "# --- load splits ---\n",
    "df_train = _load_split(cfg.train_csv)\n",
    "df_val   = _load_split(cfg.val_csv)\n",
    "df_test  = _load_split(cfg.test_csv)\n",
    "\n",
    "# --- basic stats ---\n",
    "_quick_stats(\"train\", df_train)\n",
    "_quick_stats(\"  val\", df_val)\n",
    "_quick_stats(\" test\", df_test)\n",
    "\n",
    "# --- light file checks (limit to keep fast in Jupyter) ---\n",
    "_check_files_exist(df_train)\n",
    "_check_files_exist(df_val)\n",
    "_check_files_exist(df_test)\n",
    "\n",
    "# --- leakage check if image_id is available ---\n",
    "if all((\"image_id\" in d.columns) for d in (df_train, df_val, df_test)):\n",
    "    s_tr, s_va, s_te = set(df_train.image_id), set(df_val.image_id), set(df_test.image_id)\n",
    "    inter_tr_va = s_tr & s_va\n",
    "    inter_tr_te = s_tr & s_te\n",
    "    inter_va_te = s_va & s_te\n",
    "    print(\"Leakage check by image_id:\",\n",
    "          f\"train∩val={len(inter_tr_va)} | train∩test={len(inter_tr_te)} | val∩test={len(inter_va_te)}\")\n",
    "    if inter_tr_va or inter_tr_te or inter_va_te:\n",
    "        raise AssertionError(\"Image leakage detected between splits.\")\n",
    "else:\n",
    "    print(\"Leakage check skipped (image_id column not found in all splits).\")\n",
    "\n",
    "# keep DataFrames in cfg for downstream cells\n",
    "cfg.df_train = df_train\n",
    "cfg.df_val   = df_val\n",
    "cfg.df_test  = df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fcd6b07110f7d647",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T17:21:52.672933Z",
     "start_time": "2025-09-16T17:21:52.663114Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforms ready. train_ops=4 | val_ops=1\n"
     ]
    }
   ],
   "source": [
    "# CELL 4 — Transforms (pair-synchronized for orig/mixed; no resize; 20x20 native)\n",
    "\n",
    "NORM_MEAN = (0.5, 0.5, 0.5)\n",
    "NORM_STD  = (0.5, 0.5, 0.5)\n",
    "\n",
    "def make_pair_transform(train: bool) -> A.Compose:\n",
    "    ops = []\n",
    "    if train:\n",
    "        ops += [\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.05, contrast_limit=0.05, p=0.3),\n",
    "        ]\n",
    "    ops += [A.Normalize(mean=NORM_MEAN, std=NORM_STD, max_pixel_value=255.0)]\n",
    "    # Synchronized transforms for two correlated images\n",
    "    return A.Compose(ops, additional_targets={\"mixed\": \"image\"})\n",
    "\n",
    "train_tf = make_pair_transform(train=True)\n",
    "val_tf   = make_pair_transform(train=False)\n",
    "test_tf  = val_tf\n",
    "\n",
    "def apply_pair_tf(tf: A.Compose, orig_img, mixed_img, heatmap=None):\n",
    "    \"\"\"\n",
    "    Apply identical geometry/photometric ops to orig/mixed (and optionally heatmap).\n",
    "    Works with uint8 H×W×C images.\n",
    "    Returns numpy arrays after normalization.\n",
    "    \"\"\"\n",
    "    if heatmap is None:\n",
    "        out = tf(image=orig_img, mixed=mixed_img)\n",
    "        return out[\"image\"], out[\"mixed\"], None\n",
    "    # if heatmap sync is needed:\n",
    "    tf3 = A.Compose(tf.transforms, additional_targets={\"mixed\": \"image\", \"heatmap\": \"image\"})\n",
    "    out = tf3(image=orig_img, mixed=mixed_img, heatmap=heatmap)\n",
    "    return out[\"image\"], out[\"mixed\"], out[\"heatmap\"]\n",
    "\n",
    "cfg.train_tf = train_tf\n",
    "cfg.val_tf   = val_tf\n",
    "cfg.test_tf  = test_tf\n",
    "\n",
    "print(\"Transforms ready.\",\n",
    "      f\"train_ops={len(train_tf.transforms)} | val_ops={len(val_tf.transforms)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d05c102c7ec5fdab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T17:21:52.767749Z",
     "start_time": "2025-09-16T17:21:52.754177Z"
    }
   },
   "outputs": [],
   "source": [
    "# CELL 5 — Dataset (orig, mixed, delta [+ optional gradients], y, w)\n",
    "# Loads 20×20 RGB patches, applies pair-synced transforms, builds delta and optional Sobel gradients.\n",
    "\n",
    "def _imread_rgb(path: str) -> np.ndarray:\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"Failed to read image: {path}\")\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img  # uint8 H×W×3\n",
    "\n",
    "def _infer_orig_path(mixed_path: str) -> str:\n",
    "    p = Path(mixed_path)\n",
    "    # 1) swap 'mixed_patches' -> 'orig_patches'\n",
    "    try1 = Path(str(p).replace(str(cfg.mixed_dir), str(cfg.orig_dir)))\n",
    "    if try1.exists():\n",
    "        return str(try1)\n",
    "    # 2) same filename under orig_dir\n",
    "    try2 = cfg.orig_dir / p.name\n",
    "    if try2.exists():\n",
    "        return str(try2)\n",
    "    # 3) if CSV already has orig_path column we will override in __getitem__\n",
    "    return str(try2)  # last guess; existence checked later\n",
    "\n",
    "def _to_tensor(img_f32_hwc: np.ndarray) -> torch.Tensor:\n",
    "    # input float32 H×W×C in [-1,1] after Normalize; output C×H×W\n",
    "    t = torch.from_numpy(img_f32_hwc).permute(2, 0, 1).contiguous()\n",
    "    return t\n",
    "\n",
    "def _sobel_mag(gray: np.ndarray) -> np.ndarray:\n",
    "    # gray float32 H×W in [-1,1] → magnitude in [0,1]\n",
    "    gx = cv2.Sobel(gray, cv2.CV_32F, 1, 0, ksize=3)\n",
    "    gy = cv2.Sobel(gray, cv2.CV_32F, 0, 1, ksize=3)\n",
    "    mag = np.sqrt(gx * gx + gy * gy)\n",
    "    # normalize robustly\n",
    "    m = mag.max()\n",
    "    if m > 0:\n",
    "        mag = mag / m\n",
    "    return mag\n",
    "\n",
    "def _to_gray(img_f32_hwc: np.ndarray) -> np.ndarray:\n",
    "    # img in [-1,1]; convert to gray with linear RGB weights\n",
    "    r, g, b = img_f32_hwc[..., 0], img_f32_hwc[..., 1], img_f32_hwc[..., 2]\n",
    "    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "    return gray.astype(np.float32)\n",
    "\n",
    "class BlendsPatchDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        orig_dir: Path,\n",
    "        mixed_dir: Path,\n",
    "        tf,                       # Albumentations compose (pair-synced)\n",
    "        expect_hw=(20, 20),\n",
    "        use_gradient_channels: bool = True,\n",
    "        weight_col_candidates=(\"w\", \"weight\", \"h_c\"),\n",
    "    ):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.orig_dir = Path(orig_dir)\n",
    "        self.mixed_dir = Path(mixed_dir)\n",
    "        self.tf = tf\n",
    "        self.expect_hw = expect_hw\n",
    "        self.use_grads = bool(use_gradient_channels and getattr(cfg, \"push99\", SimpleNamespace(use_gradient_channels=False)).use_gradient_channels)\n",
    "        self.weight_cols = [c for c in weight_col_candidates if c in self.df.columns]\n",
    "        # precompute simple min/max if we will normalize a weight column not in [0,1]\n",
    "        self._norm_stats = {}\n",
    "        for c in self.weight_cols:\n",
    "            v = self.df[c].astype(\"float32\").to_numpy()\n",
    "            vmin, vmax = float(np.nanmin(v)), float(np.nanmax(v))\n",
    "            self._norm_stats[c] = (vmin, vmax)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def _resolve_paths(self, row) -> tuple[str, str]:\n",
    "        mixed_path = str(row[\"mixed_path\"])\n",
    "        if \"orig_path\" in row and isinstance(row[\"orig_path\"], str) and len(row[\"orig_path\"]) > 0:\n",
    "            orig_path = row[\"orig_path\"]\n",
    "        else:\n",
    "            orig_path = _infer_orig_path(mixed_path)\n",
    "        if not Path(mixed_path).exists():\n",
    "            raise FileNotFoundError(f\"mixed_path not found: {mixed_path}\")\n",
    "        if not Path(orig_path).exists():\n",
    "            raise FileNotFoundError(f\"orig_path not found: {orig_path}\")\n",
    "        return orig_path, mixed_path\n",
    "\n",
    "    def _weight_from_row(self, row) -> float:\n",
    "        if not self.weight_cols:\n",
    "            return 1.0\n",
    "        c = self.weight_cols[0]\n",
    "        val = float(row[c])\n",
    "        vmin, vmax = self._norm_stats[c]\n",
    "        if vmax > vmin:\n",
    "            val = (val - vmin) / (vmax - vmin)\n",
    "        return float(np.clip(val, 0.0, 1.0))\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        row = self.df.iloc[idx]\n",
    "        y = float(row[\"target\"])\n",
    "        w = self._weight_from_row(row) if getattr(cfg, \"push99\", SimpleNamespace(use_heatmap_weighting=False)).use_heatmap_weighting else 1.0\n",
    "\n",
    "        orig_path, mixed_path = self._resolve_paths(row)\n",
    "        orig = _imread_rgb(orig_path)\n",
    "        mixed = _imread_rgb(mixed_path)\n",
    "\n",
    "        # sanity: expect exact 20×20\n",
    "        H, W = orig.shape[:2]\n",
    "        if (H, W) != self.expect_hw:\n",
    "            raise AssertionError(f\"Unexpected orig patch size {orig.shape} at {orig_path}\")\n",
    "        if mixed.shape[:2] != (H, W):\n",
    "            raise AssertionError(f\"Size mismatch orig {orig.shape} vs mixed {mixed.shape}\")\n",
    "\n",
    "        # pair-synchronized transforms → float32 H×W×C in [-1,1] after Normalize\n",
    "        orig_f, mixed_f, _ = apply_pair_tf(self.tf, orig, mixed, heatmap=None)\n",
    "\n",
    "        # delta after identical transforms\n",
    "        delta_f = (mixed_f - orig_f).astype(np.float32)\n",
    "\n",
    "        # optional gradient channels\n",
    "        grads_t = None\n",
    "        if self.use_grads:\n",
    "            g_orig = _sobel_mag(_to_gray(orig_f))\n",
    "            g_mixed = _sobel_mag(_to_gray(mixed_f))\n",
    "            g_delta = _sobel_mag(_to_gray(delta_f))\n",
    "            # stack to C×H×W\n",
    "            g_stack = np.stack([g_orig, g_mixed, g_delta], axis=-1).astype(np.float32)\n",
    "            grads_t = _to_tensor(g_stack)\n",
    "\n",
    "        # to tensors C×H×W\n",
    "        orig_t  = _to_tensor(orig_f.astype(np.float32))\n",
    "        mixed_t = _to_tensor(mixed_f.astype(np.float32))\n",
    "        delta_t = _to_tensor(delta_f)\n",
    "\n",
    "        sample = {\n",
    "            \"orig\": orig_t,\n",
    "            \"mixed\": mixed_t,\n",
    "            \"delta\": delta_t,\n",
    "            \"y\": torch.tensor([y], dtype=torch.float32),\n",
    "            \"w\": torch.tensor([w], dtype=torch.float32),\n",
    "        }\n",
    "        if grads_t is not None:\n",
    "            sample[\"grads\"] = grads_t  # 3×H×W\n",
    "\n",
    "        # optional metadata for debugging\n",
    "        if \"image_id\" in self.df.columns:\n",
    "            sample[\"image_id\"] = row[\"image_id\"]\n",
    "\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3942385449453a9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T17:21:53.188380Z",
     "start_time": "2025-09-16T17:21:52.858103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loader: n_batches≈15 | batch=128 | orig=(128, 3, 20, 20) mixed=(128, 3, 20, 20) delta=(128, 3, 20, 20) | grads=yes (128, 3, 20, 20) | y=(128, 1) w=(128, 1)\n",
      "val_loader: n_batches≈3 | batch=128 | orig=(128, 3, 20, 20) mixed=(128, 3, 20, 20) delta=(128, 3, 20, 20) | grads=yes (128, 3, 20, 20) | y=(128, 1) w=(128, 1)\n",
      "test_loader: n_batches≈3 | batch=128 | orig=(128, 3, 20, 20) mixed=(128, 3, 20, 20) delta=(128, 3, 20, 20) | grads=yes (128, 3, 20, 20) | y=(128, 1) w=(128, 1)\n"
     ]
    }
   ],
   "source": [
    "# CELL 6 — DataSets & DataLoaders\n",
    "# Build train/val/test datasets. Duplicate train set via stochastic augmentation.\n",
    "# Jupyter-friendly: num_workers=0. Prints quick loader stats.\n",
    "\n",
    "from torch.utils.data import ConcatDataset, DataLoader\n",
    "\n",
    "# --- datasets ---\n",
    "train_parts = [BlendsPatchDataset(\n",
    "    cfg.df_train, cfg.orig_dir, cfg.mixed_dir, tf=cfg.train_tf,\n",
    "    use_gradient_channels=True\n",
    ") for _ in range(1 + int(cfg.aug_dup))]  # base + aug duplicates\n",
    "\n",
    "train_ds = ConcatDataset(train_parts)\n",
    "val_ds   = BlendsPatchDataset(cfg.df_val,  cfg.orig_dir, cfg.mixed_dir, tf=cfg.val_tf,  use_gradient_channels=True)\n",
    "test_ds  = BlendsPatchDataset(cfg.df_test, cfg.orig_dir, cfg.mixed_dir, tf=cfg.test_tf, use_gradient_channels=True)\n",
    "\n",
    "# --- loaders ---\n",
    "pin = bool(cfg.device == \"cuda\")\n",
    "train_loader = DataLoader(train_ds, batch_size=cfg.batch_size, shuffle=True,\n",
    "                          num_workers=cfg.num_workers, pin_memory=pin, drop_last=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=cfg.batch_size, shuffle=False,\n",
    "                          num_workers=cfg.num_workers, pin_memory=pin)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=cfg.batch_size, shuffle=False,\n",
    "                          num_workers=cfg.num_workers, pin_memory=pin)\n",
    "\n",
    "# --- debug peek ---\n",
    "def _peek(loader, name):\n",
    "    try:\n",
    "        batch = next(iter(loader))\n",
    "        o, m, d = batch[\"orig\"], batch[\"mixed\"], batch[\"delta\"]\n",
    "        g = batch.get(\"grads\", None)\n",
    "        y, w = batch[\"y\"], batch[\"w\"]\n",
    "        print(f\"{name}: n_batches≈{len(loader)} | batch={o.shape[0]} \"\n",
    "              f\"| orig={tuple(o.shape)} mixed={tuple(m.shape)} delta={tuple(d.shape)} \"\n",
    "              f\"| grads={'yes '+str(tuple(g.shape)) if g is not None else 'no'} \"\n",
    "              f\"| y={tuple(y.shape)} w={tuple(w.shape)}\")\n",
    "    except StopIteration:\n",
    "        print(f\"{name}: empty.\")\n",
    "\n",
    "_peek(train_loader, \"train_loader\")\n",
    "_peek(val_loader,   \"val_loader\")\n",
    "_peek(test_loader,  \"test_loader\")\n",
    "\n",
    "# expose in cfg\n",
    "cfg.train_loader = train_loader\n",
    "cfg.val_loader   = val_loader\n",
    "cfg.test_loader  = test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b5096d8658fb489",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T17:21:53.285544Z",
     "start_time": "2025-09-16T17:21:53.267119Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DualBranchIQAModel | params: 250945\n"
     ]
    }
   ],
   "source": [
    "# CELL 7 — Model (20×20 dual-branch with optional gradient channels)\n",
    "# Two CNN branches for ORIG and MIXED, a light path for DELTA, optional path for GRADS.\n",
    "# Fusion → Conv → GAP → MLP regression head.\n",
    "\n",
    "from types import SimpleNamespace\n",
    "\n",
    "def conv_block(in_ch, out_ch, k=3, s=1, p=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_ch, out_ch, kernel_size=k, stride=s, padding=p, bias=True),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\n",
    "\n",
    "class SmallBackbone(nn.Module):\n",
    "    def __init__(self, in_ch):\n",
    "        super().__init__()\n",
    "        self.b1 = conv_block(in_ch, 32)\n",
    "        self.b2 = conv_block(32, 32)\n",
    "        self.pool = nn.MaxPool2d(2)  # 20→10\n",
    "        self.b3 = conv_block(32, 64)\n",
    "    def forward(self, x):\n",
    "        x = self.b1(x)\n",
    "        x = self.b2(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.b3(x)\n",
    "        return x  # [B,64,10,10]\n",
    "\n",
    "class LightPath(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch=16):\n",
    "        super().__init__()\n",
    "        self.net = conv_block(in_ch, out_ch)\n",
    "    def forward(self, x):\n",
    "        return self.net(x)  # keep spatial 20×20 or 10×10 per input\n",
    "\n",
    "class DualBranchIQAModel(nn.Module):\n",
    "    def __init__(self, use_grads: bool = False, in_ch_rgb: int = 3, in_ch_delta: int = 3, in_ch_grads: int = 3):\n",
    "        super().__init__()\n",
    "        # main branches (operate on 20→10 spatial)\n",
    "        self.orig_backbone  = SmallBackbone(in_ch=in_ch_rgb)\n",
    "        self.mixed_backbone = SmallBackbone(in_ch=in_ch_rgb)\n",
    "        # delta path (keep 20, then down to match 10×10)\n",
    "        self.delta_path = LightPath(in_ch=in_ch_delta, out_ch=16)\n",
    "        self.delta_pool = nn.MaxPool2d(2)  # 20→10\n",
    "\n",
    "        self.use_grads = bool(use_grads)\n",
    "        if self.use_grads:\n",
    "            self.grads_path = LightPath(in_ch=in_ch_grads, out_ch=16)\n",
    "            self.grads_pool = nn.MaxPool2d(2)\n",
    "\n",
    "        # fusion\n",
    "        fuse_in = 64 + 64 + 16 + (16 if self.use_grads else 0)  # [orig,mixed,delta,(grads)]\n",
    "        self.fuse = conv_block(fuse_in, 128)\n",
    "        self.gap  = nn.AdaptiveAvgPool2d(1)  # → [B,128,1,1]\n",
    "\n",
    "        # head\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Flatten(),                 # [B,128]\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity=\"relu\")\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_uniform_(m.weight, nonlinearity=\"relu\")\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, orig, mixed, delta, grads=None):\n",
    "        fo = self.orig_backbone(orig)     # [B,64,10,10]\n",
    "        fm = self.mixed_backbone(mixed)   # [B,64,10,10]\n",
    "\n",
    "        fd = self.delta_path(delta)       # [B,16,20,20]\n",
    "        fd = self.delta_pool(fd)          # [B,16,10,10]\n",
    "\n",
    "        parts = [fo, fm, fd]\n",
    "\n",
    "        if self.use_grads:\n",
    "            if grads is None:\n",
    "                raise ValueError(\"Model configured with use_grads=True but no grads tensor was provided.\")\n",
    "            fg = self.grads_path(grads)   # [B,16,20,20]\n",
    "            fg = self.grads_pool(fg)      # [B,16,10,10]\n",
    "            parts.append(fg)\n",
    "\n",
    "        x = torch.cat(parts, dim=1)       # [B, fuse_in, 10,10]\n",
    "        x = self.fuse(x)                  # [B,128,10,10]\n",
    "        x = self.gap(x)                   # [B,128,1,1]\n",
    "        out = torch.sigmoid(self.head(x))               # [B,1]\n",
    "        return out\n",
    "\n",
    "# instantiate\n",
    "push99 = getattr(cfg, \"push99\", SimpleNamespace())\n",
    "use_grads = bool(getattr(push99, \"use_gradient_channels\", False))\n",
    "\n",
    "model = DualBranchIQAModel(use_grads=use_grads).to(cfg.device)\n",
    "\n",
    "\n",
    "def count_params(m: nn.Module) -> int:\n",
    "    return sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
    "\n",
    "print(model.__class__.__name__, \"| params:\", count_params(model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48988ad18b658c36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T17:21:53.540504Z",
     "start_time": "2025-09-16T17:21:53.504494Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torchinfo] skipped: 'param_numbers' is not a valid RowSettings\n",
      "[torchviz] skipped: failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH\n",
      "[torchview] skipped: Failed to run torchgraph see error message\n"
     ]
    }
   ],
   "source": [
    "# Cell 8 — Visualize DualBranchIQAModel (graph + architecture + layer table)\n",
    "# Assumes `model = DualBranchIQAModel(...).to(cfg.device)` was created in Cell 7.\n",
    "\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "model.eval()\n",
    "dev = next(model.parameters()).device  # cpu or cuda:0\n",
    "\n",
    "# ---------- dummy inputs on the same device ----------\n",
    "B, C, H, W = 1, 3, 20, 20\n",
    "orig  = torch.randn(B, C, H, W, device=dev)\n",
    "mixed = torch.randn(B, C, H, W, device=dev)\n",
    "delta = torch.abs(mixed - orig)\n",
    "\n",
    "use_grads = getattr(model, \"use_grads\", False)\n",
    "if use_grads:\n",
    "    grads = torch.randn(B, C, H, W, device=dev)\n",
    "    input_args = (orig, mixed, delta, grads)\n",
    "else:\n",
    "    input_args = (orig, mixed, delta)\n",
    "\n",
    "# output dirs\n",
    "Path(\"reports\").mkdir(exist_ok=True)\n",
    "\n",
    "# ---------- C) Layer table (torchinfo) ----------\n",
    "try:\n",
    "    from torchinfo import summary\n",
    "    table = summary(model,\n",
    "                    input_data=input_args,\n",
    "                    depth=5,\n",
    "                    col_names=(\"input_size\",\"output_size\",\"kernel_size\",\"num_params\",\"mult_adds\"),\n",
    "                    row_settings=(\"var_names\",\"depth\",\"param_numbers\"))\n",
    "    with open(\"reports/model_summary.txt\", \"w\") as f:\n",
    "        f.write(str(table))\n",
    "    with open(\"reports/model_summary.md\", \"w\") as f:\n",
    "        f.write(\"```text\\n\"); f.write(str(table)); f.write(\"\\n```\")\n",
    "    print(\"Saved: reports/model_summary.txt, reports/model_summary.md\")\n",
    "except Exception as e:\n",
    "    print(\"[torchinfo] skipped:\", e)\n",
    "\n",
    "# ---------- A) Computation graph (torchviz → SVG/PNG) ----------\n",
    "try:\n",
    "    from torchviz import make_dot\n",
    "    with torch.no_grad():\n",
    "        y = model(*input_args)\n",
    "    dot = make_dot(y, params=dict(model.named_parameters()),\n",
    "                   show_attrs=False, show_saved=False)\n",
    "    dot.format = \"svg\"\n",
    "    dot.render(\"reports/locjnd_regression_graph\", cleanup=True)  # -> .svg\n",
    "    dot_png = make_dot(y, params=dict(model.named_parameters()),\n",
    "                       show_attrs=False, show_saved=False)\n",
    "    dot_png.format = \"png\"\n",
    "    dot_png.render(\"reports/locjnd_regression_graph\", cleanup=True)  # -> .png\n",
    "    print(\"Saved: reports/locjnd_regression_graph.svg, reports/locjnd_regression_graph.png\")\n",
    "except Exception as e:\n",
    "    print(\"[torchviz] skipped:\", e)\n",
    "\n",
    "# ---------- B) Architecture diagram (torchview → PNG) ----------\n",
    "try:\n",
    "    from torchview import draw_graph\n",
    "    g = draw_graph(model,\n",
    "                   input_data=input_args,\n",
    "                   expand_nested=True,\n",
    "                   graph_name=\"LocJND_Regression\",\n",
    "                   save_graph=True,\n",
    "                   filename=\"locjnd_architecture\",\n",
    "                   directory=\"reports\",\n",
    "                   format=\"png\")\n",
    "    print(\"Saved: reports/locjnd_architecture.png\")\n",
    "except Exception as e:\n",
    "    print(\"[torchview] skipped:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75880e08a235010",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T17:21:53.664768Z",
     "start_time": "2025-09-16T17:21:53.544208Z"
    }
   },
   "outputs": [],
   "source": [
    "# CELL 8 — Losses & Metrics\n",
    "\n",
    "from types import SimpleNamespace\n",
    "\n",
    "EPS = 1e-8\n",
    "_rank = nn.MarginRankingLoss(margin=0.05)\n",
    "\n",
    "def _flat(x):\n",
    "    return x.view(-1)\n",
    "\n",
    "def rmse(yhat, y):\n",
    "    e = (_flat(yhat) - _flat(y)) ** 2\n",
    "    return torch.sqrt(e.mean())\n",
    "\n",
    "def plcc(yhat, y):\n",
    "    x = _flat(yhat); t = _flat(y)\n",
    "    x = x - x.mean()\n",
    "    t = t - t.mean()\n",
    "    vx = x.pow(2).mean()\n",
    "    vt = t.pow(2).mean()\n",
    "    denom = torch.sqrt(vx * vt) + EPS\n",
    "    return (x * t).mean() / denom\n",
    "\n",
    "def pearson_loss(yhat, y):\n",
    "    return 1.0 - plcc(yhat, y)\n",
    "\n",
    "def weighted_mse(yhat, y, w=None, use_weights=False):\n",
    "    e = (_flat(yhat) - _flat(y)) ** 2\n",
    "    if use_weights and w is not None:\n",
    "        w = _flat(w)\n",
    "        return (w * e).sum() / (w.sum() + EPS)\n",
    "    return e.mean()\n",
    "\n",
    "def ranking_loss(yhat, y):\n",
    "    x = _flat(yhat); t = _flat(y)\n",
    "    n = x.numel()\n",
    "    if n < 2:\n",
    "        return x.new_tensor(0.0)\n",
    "\n",
    "    perm = torch.randperm(n, device=x.device)\n",
    "    half = n // 2\n",
    "    i = perm[:half]\n",
    "    j = perm[half:half + half]\n",
    "    if j.numel() < i.numel():\n",
    "        i = i[:j.numel()]\n",
    "\n",
    "    s = torch.sign(t[i] - t[j])  # +1 if y_i > y_j, -1 if y_i < y_j\n",
    "    m = s != 0\n",
    "    if m.sum() == 0:\n",
    "        return x.new_tensor(0.0)\n",
    "    return _rank(x[i][m], x[j][m], s[m])\n",
    "\n",
    "push99 = getattr(cfg, \"push99\", SimpleNamespace(lambda_rank=0.1, lambda_pearson=0.1, use_heatmap_weighting=False))\n",
    "\n",
    "class LossBundle:\n",
    "    def __init__(self, push):\n",
    "        self.lambda_rank = float(getattr(push, \"lambda_rank\", 0.2))\n",
    "        self.lambda_pearson = float(getattr(push, \"lambda_pearson\", 0.0))\n",
    "        self.use_w = bool(getattr(push, \"use_heatmap_weighting\", False))\n",
    "\n",
    "    def __call__(self, yhat, y, w=None):\n",
    "        mse = weighted_mse(yhat, y, w, self.use_w)\n",
    "        rnk = ranking_loss(yhat, y)\n",
    "        prc = pearson_loss(yhat, y) if self.lambda_pearson > 0 else yhat.new_tensor(0.0)\n",
    "        total = mse + self.lambda_rank * rnk + self.lambda_pearson * prc\n",
    "        parts = {\"mse\": mse.detach(), \"rank\": rnk.detach(), \"pearson\": prc.detach()}\n",
    "        return total, parts\n",
    "\n",
    "loss_bundle = LossBundle(push99)\n",
    "\n",
    "def compute_metrics(yhat, y):\n",
    "    return {\"rmse\": rmse(yhat, y).item(), \"plcc\": plcc(yhat, y).item()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff37d93923cfe13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T17:21:53.748145Z",
     "start_time": "2025-09-16T17:21:53.742107Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer: Adam | init_lr=0.0001 | weight_decay=0.0001\n",
      "Scheduler: warmup=3 epochs → cosine over 37\n",
      "AMP enabled: True\n"
     ]
    }
   ],
   "source": [
    "# CELL 9 — Optimizer, Scheduler (warmup+cosine), AMP\n",
    "\n",
    "import math\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "# --- optimizer ---\n",
    "optimizer = Adam(model.parameters(), lr=cfg.lr_init, weight_decay=cfg.weight_decay)\n",
    "\n",
    "# --- scheduler: linear warmup → cosine decay ---\n",
    "warmup_epochs = getattr(cfg, \"warmup_epochs\", 3)\n",
    "total_epochs  = int(cfg.epochs)\n",
    "\n",
    "def _lr_lambda(epoch: int):\n",
    "    if warmup_epochs > 0 and epoch < warmup_epochs:\n",
    "        return float(epoch + 1) / float(max(1, warmup_epochs))\n",
    "    # cosine on the remaining epochs (inclusive of last epoch index)\n",
    "    t = (epoch - warmup_epochs) / max(1, (total_epochs - warmup_epochs))\n",
    "    return 0.5 * (1.0 + math.cos(math.pi * min(1.0, max(0.0, t))))\n",
    "\n",
    "scheduler = LambdaLR(optimizer, lr_lambda=_lr_lambda)\n",
    "\n",
    "# --- AMP scaler ---\n",
    "use_amp = (cfg.device == \"cuda\")\n",
    "scaler = torch.amp.GradScaler(enabled=use_amp)\n",
    "\n",
    "def current_lr(optim=optimizer) -> float:\n",
    "    return float(optim.param_groups[0][\"lr\"])\n",
    "\n",
    "print(f\"Optimizer: Adam | init_lr={cfg.lr_init} | weight_decay={cfg.weight_decay}\")\n",
    "print(f\"Scheduler: warmup={warmup_epochs} epochs → cosine over {total_epochs - warmup_epochs}\")\n",
    "print(f\"AMP enabled: {use_amp}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4a7185c7f826e1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T17:23:42.527201Z",
     "start_time": "2025-09-16T17:21:53.839401Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 001] train_loss=0.2391 | train_PLCC=-0.026 | val_RMSE=0.343 val_PLCC=-0.046 | lr=6.667e-05\n",
      "[Epoch 002] train_loss=0.2124 | train_PLCC=0.130 | val_RMSE=0.338 val_PLCC=0.250 | lr=1.000e-04\n",
      "[Epoch 003] train_loss=0.1884 | train_PLCC=0.286 | val_RMSE=0.330 val_PLCC=0.306 | lr=1.000e-04\n",
      "[Epoch 004] train_loss=0.1646 | train_PLCC=0.449 | val_RMSE=0.328 val_PLCC=0.544 | lr=9.982e-05\n",
      "[Epoch 005] train_loss=0.1458 | train_PLCC=0.585 | val_RMSE=0.316 val_PLCC=0.635 | lr=9.928e-05\n",
      "[Epoch 006] train_loss=0.1332 | train_PLCC=0.654 | val_RMSE=0.307 val_PLCC=0.700 | lr=9.839e-05\n",
      "[Epoch 007] train_loss=0.1248 | train_PLCC=0.710 | val_RMSE=0.303 val_PLCC=0.754 | lr=9.714e-05\n",
      "[Epoch 008] train_loss=0.1177 | train_PLCC=0.744 | val_RMSE=0.297 val_PLCC=0.775 | lr=9.556e-05\n",
      "[Epoch 009] train_loss=0.1103 | train_PLCC=0.771 | val_RMSE=0.289 val_PLCC=0.802 | lr=9.365e-05\n",
      "[Epoch 010] train_loss=0.1074 | train_PLCC=0.759 | val_RMSE=0.283 val_PLCC=0.791 | lr=9.143e-05\n",
      "[Epoch 011] train_loss=0.1029 | train_PLCC=0.771 | val_RMSE=0.271 val_PLCC=0.818 | lr=8.890e-05\n",
      "[Epoch 012] train_loss=0.0961 | train_PLCC=0.782 | val_RMSE=0.268 val_PLCC=0.822 | lr=8.610e-05\n",
      "[Epoch 013] train_loss=0.0893 | train_PLCC=0.817 | val_RMSE=0.258 val_PLCC=0.827 | lr=8.303e-05\n",
      "[Epoch 014] train_loss=0.0844 | train_PLCC=0.822 | val_RMSE=0.256 val_PLCC=0.834 | lr=7.973e-05\n",
      "[Epoch 015] train_loss=0.0790 | train_PLCC=0.827 | val_RMSE=0.246 val_PLCC=0.836 | lr=7.622e-05\n",
      "[Epoch 016] train_loss=0.0751 | train_PLCC=0.842 | val_RMSE=0.246 val_PLCC=0.826 | lr=7.251e-05\n",
      "[Epoch 017] train_loss=0.0721 | train_PLCC=0.841 | val_RMSE=0.235 val_PLCC=0.834 | lr=6.864e-05\n",
      "[Epoch 018] train_loss=0.0686 | train_PLCC=0.848 | val_RMSE=0.229 val_PLCC=0.833 | lr=6.464e-05\n",
      "[Epoch 019] train_loss=0.0641 | train_PLCC=0.856 | val_RMSE=0.228 val_PLCC=0.829 | lr=6.053e-05\n",
      "[Epoch 020] train_loss=0.0608 | train_PLCC=0.856 | val_RMSE=0.229 val_PLCC=0.830 | lr=5.635e-05\n",
      "[Epoch 021] train_loss=0.0579 | train_PLCC=0.866 | val_RMSE=0.225 val_PLCC=0.828 | lr=5.212e-05\n",
      "[Epoch 022] train_loss=0.0540 | train_PLCC=0.876 | val_RMSE=0.221 val_PLCC=0.821 | lr=4.788e-05\n",
      "[Epoch 023] train_loss=0.0524 | train_PLCC=0.875 | val_RMSE=0.225 val_PLCC=0.829 | lr=4.365e-05\n",
      "[Epoch 024] train_loss=0.0505 | train_PLCC=0.875 | val_RMSE=0.223 val_PLCC=0.820 | lr=3.947e-05\n",
      "[Epoch 025] train_loss=0.0505 | train_PLCC=0.875 | val_RMSE=0.216 val_PLCC=0.821 | lr=3.536e-05\n",
      "[Epoch 026] train_loss=0.0484 | train_PLCC=0.877 | val_RMSE=0.211 val_PLCC=0.822 | lr=3.136e-05\n",
      "[Epoch 027] train_loss=0.0480 | train_PLCC=0.879 | val_RMSE=0.215 val_PLCC=0.818 | lr=2.749e-05\n",
      "[Epoch 028] train_loss=0.0460 | train_PLCC=0.885 | val_RMSE=0.212 val_PLCC=0.820 | lr=2.378e-05\n",
      "[Epoch 029] train_loss=0.0455 | train_PLCC=0.890 | val_RMSE=0.218 val_PLCC=0.818 | lr=2.027e-05\n",
      "[Epoch 030] train_loss=0.0439 | train_PLCC=0.893 | val_RMSE=0.214 val_PLCC=0.818 | lr=1.697e-05\n",
      "[Epoch 031] train_loss=0.0445 | train_PLCC=0.888 | val_RMSE=0.215 val_PLCC=0.816 | lr=1.390e-05\n",
      "[Epoch 032] train_loss=0.0441 | train_PLCC=0.890 | val_RMSE=0.212 val_PLCC=0.817 | lr=1.110e-05\n",
      "[Epoch 033] train_loss=0.0434 | train_PLCC=0.889 | val_RMSE=0.216 val_PLCC=0.815 | lr=8.575e-06\n",
      "[Epoch 034] train_loss=0.0429 | train_PLCC=0.893 | val_RMSE=0.213 val_PLCC=0.818 | lr=6.349e-06\n",
      "[Epoch 035] train_loss=0.0425 | train_PLCC=0.895 | val_RMSE=0.214 val_PLCC=0.816 | lr=4.439e-06\n",
      "[Epoch 036] train_loss=0.0427 | train_PLCC=0.893 | val_RMSE=0.214 val_PLCC=0.816 | lr=2.856e-06\n",
      "[Epoch 037] train_loss=0.0435 | train_PLCC=0.892 | val_RMSE=0.214 val_PLCC=0.816 | lr=1.613e-06\n",
      "[Epoch 038] train_loss=0.0418 | train_PLCC=0.896 | val_RMSE=0.214 val_PLCC=0.816 | lr=7.192e-07\n",
      "[Epoch 039] train_loss=0.0430 | train_PLCC=0.891 | val_RMSE=0.214 val_PLCC=0.816 | lr=1.801e-07\n",
      "[Epoch 040] train_loss=0.0421 | train_PLCC=0.895 | val_RMSE=0.214 val_PLCC=0.816 | lr=0.000e+00\n",
      "Best val_RMSE=0.2115 at epoch 26\n"
     ]
    }
   ],
   "source": [
    "# CELL 10 — Train/Val Loop\n",
    "# Prints per-epoch progress.\n",
    "\n",
    "import time\n",
    "\n",
    "def _move_to_device(batch, device):\n",
    "    orig  = batch[\"orig\"].to(device, non_blocking=True)\n",
    "    mixed = batch[\"mixed\"].to(device, non_blocking=True)\n",
    "    delta = batch[\"delta\"].to(device, non_blocking=True)\n",
    "    grads = batch.get(\"grads\", None)\n",
    "    if grads is not None:\n",
    "        grads = grads.to(device, non_blocking=True)\n",
    "    y = batch[\"y\"].to(device)\n",
    "    w = batch[\"w\"].to(device)\n",
    "    return orig, mixed, delta, grads, y, w\n",
    "\n",
    "def train_one_epoch(epoch_idx: int):\n",
    "    model.train()\n",
    "    total_loss = []\n",
    "    yh_all, y_all = [], []\n",
    "\n",
    "    for batch in cfg.train_loader:\n",
    "        orig, mixed, delta, grads, y, w = _move_to_device(batch, cfg.device)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.amp.autocast(\"cuda\", enabled=use_amp):\n",
    "            yhat = model(orig, mixed, delta, grads)\n",
    "            loss, _ = loss_bundle(yhat, y, w=w)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss.append(loss.detach().item())\n",
    "        yh_all.append(yhat.detach())\n",
    "        y_all.append(y.detach())\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    yhat_cat = torch.cat(yh_all, 0)\n",
    "    y_cat    = torch.cat(y_all, 0)\n",
    "    metrics  = compute_metrics(yhat_cat, y_cat)\n",
    "\n",
    "    return float(np.mean(total_loss)), metrics\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    yh_all, y_all = [], []\n",
    "    losses = []\n",
    "\n",
    "    for batch in loader:\n",
    "        orig, mixed, delta, grads, y, w = _move_to_device(batch, cfg.device)\n",
    "        yhat = model(orig, mixed, delta, grads)\n",
    "        l, _ = loss_bundle(yhat, y, w=w)\n",
    "        losses.append(l.detach().item())\n",
    "        yh_all.append(yhat.detach())\n",
    "        y_all.append(y.detach())\n",
    "\n",
    "    yhat_cat = torch.cat(yh_all, 0)\n",
    "    y_cat    = torch.cat(y_all, 0)\n",
    "    metrics  = compute_metrics(yhat_cat, y_cat)\n",
    "    return float(np.mean(losses)), metrics\n",
    "\n",
    "best_val_rmse = float(\"inf\")\n",
    "best_epoch = -1\n",
    "\n",
    "for epoch in range(int(cfg.epochs)):\n",
    "    t0 = time.time()\n",
    "    train_loss, train_m = train_one_epoch(epoch)\n",
    "    val_loss,   val_m   = evaluate(cfg.val_loader)\n",
    "\n",
    "    lr_now = current_lr(optimizer)\n",
    "    print(f\"[Epoch {epoch+1:03d}] \"\n",
    "          f\"train_loss={train_loss:.4f} | train_PLCC={train_m['plcc']:.3f} \"\n",
    "          f\"| val_RMSE={val_m['rmse']:.3f} val_PLCC={val_m['plcc']:.3f} \"\n",
    "          f\"| lr={lr_now:.3e}\")\n",
    "\n",
    "    if val_m[\"rmse\"] < best_val_rmse:\n",
    "        best_val_rmse = val_m[\"rmse\"]\n",
    "        best_epoch = epoch + 1\n",
    "\n",
    "print(f\"Best val_RMSE={best_val_rmse:.4f} at epoch {best_epoch}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb16f4cc91eb1f2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T17:24:10.720901Z",
     "start_time": "2025-09-16T17:23:42.694719Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 001] train_loss=0.0417 | train_PLCC=0.895 | val_RMSE=0.214 val_PLCC=0.816 | lr=0.000e+00 | 2.5s\n",
      "  ↳ saved best checkpoint @ epoch 1 (val_RMSE=0.2138)\n",
      "[Epoch 002] train_loss=0.0425 | train_PLCC=0.892 | val_RMSE=0.214 val_PLCC=0.816 | lr=0.000e+00 | 2.5s\n",
      "[Epoch 003] train_loss=0.0433 | train_PLCC=0.893 | val_RMSE=0.214 val_PLCC=0.816 | lr=0.000e+00 | 2.6s\n",
      "[Epoch 004] train_loss=0.0420 | train_PLCC=0.895 | val_RMSE=0.214 val_PLCC=0.816 | lr=0.000e+00 | 2.5s\n",
      "[Epoch 005] train_loss=0.0415 | train_PLCC=0.895 | val_RMSE=0.214 val_PLCC=0.816 | lr=0.000e+00 | 2.5s\n",
      "[Epoch 006] train_loss=0.0431 | train_PLCC=0.892 | val_RMSE=0.214 val_PLCC=0.816 | lr=0.000e+00 | 2.5s\n",
      "[Epoch 007] train_loss=0.0421 | train_PLCC=0.896 | val_RMSE=0.214 val_PLCC=0.816 | lr=0.000e+00 | 2.5s\n",
      "[Epoch 008] train_loss=0.0418 | train_PLCC=0.892 | val_RMSE=0.214 val_PLCC=0.816 | lr=0.000e+00 | 2.5s\n",
      "[Epoch 009] train_loss=0.0426 | train_PLCC=0.893 | val_RMSE=0.214 val_PLCC=0.816 | lr=0.000e+00 | 2.5s\n",
      "[Epoch 010] train_loss=0.0430 | train_PLCC=0.890 | val_RMSE=0.214 val_PLCC=0.816 | lr=0.000e+00 | 2.5s\n",
      "[Epoch 011] train_loss=0.0414 | train_PLCC=0.896 | val_RMSE=0.214 val_PLCC=0.816 | lr=0.000e+00 | 2.6s\n",
      "Early stopping after 11 epochs (no improvement for 10).\n",
      "Best val_RMSE=0.2138 at epoch 1\n",
      "best: checkpoints\\20250916-202151\\best.ckpt\n",
      "last: checkpoints\\20250916-202151\\last.ckpt\n"
     ]
    }
   ],
   "source": [
    "# CELL 11 — Checkpointing + Early Stopping (self-contained training wrapper)\n",
    "# Saves best (by min val_RMSE) and last checkpoints. Early-stops on patience.\n",
    "\n",
    "import time\n",
    "from types import SimpleNamespace\n",
    "\n",
    "ckpt_dir = cfg.checkpoints_dir / cfg.run_id\n",
    "ckpt_dir.mkdir(parents=True, exist_ok=True)\n",
    "best_ckpt_path = ckpt_dir / \"best.ckpt\"\n",
    "last_ckpt_path = ckpt_dir / \"last.ckpt\"\n",
    "\n",
    "def save_checkpoint(path: Path, epoch: int, best_val_rmse: float):\n",
    "    torch.save({\n",
    "        \"epoch\": epoch,\n",
    "        \"model\": model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "        \"scheduler\": scheduler.state_dict(),\n",
    "        \"scaler\": scaler.state_dict() if 'scaler' in globals() else None,\n",
    "        \"best_val_rmse\": best_val_rmse,\n",
    "        \"run_id\": cfg.run_id,\n",
    "    }, path)\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience: int = 10, min_delta: float = 1e-6):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best = float(\"inf\")\n",
    "        self.count = 0\n",
    "    def step(self, val_rmse: float) -> bool:\n",
    "        if val_rmse < self.best - self.min_delta:\n",
    "            self.best = val_rmse\n",
    "            self.count = 0\n",
    "            return False\n",
    "        self.count += 1\n",
    "        return self.count >= self.patience  # True => stop\n",
    "\n",
    "def train_with_ckpt(patience: int = 10):\n",
    "    stopper = EarlyStopper(patience=patience)\n",
    "    best_val = float(\"inf\")\n",
    "    best_epoch = -1\n",
    "\n",
    "    for epoch in range(int(cfg.epochs)):\n",
    "        t0 = time.time()\n",
    "        train_loss, train_m = train_one_epoch(epoch)\n",
    "        val_loss,   val_m   = evaluate(cfg.val_loader)\n",
    "\n",
    "        # scheduler already stepped inside train_one_epoch; if moved out, keep scheduler.step() here.\n",
    "        lr_now = current_lr(optimizer)\n",
    "        print(f\"[Epoch {epoch+1:03d}] \"\n",
    "              f\"train_loss={train_loss:.4f} | train_PLCC={train_m['plcc']:.3f} \"\n",
    "              f\"| val_RMSE={val_m['rmse']:.3f} val_PLCC={val_m['plcc']:.3f} \"\n",
    "              f\"| lr={lr_now:.3e} | {time.time()-t0:.1f}s\")\n",
    "\n",
    "        # always save 'last'\n",
    "        save_checkpoint(last_ckpt_path, epoch+1, best_val)\n",
    "\n",
    "        # update 'best'\n",
    "        if val_m[\"rmse\"] < best_val:\n",
    "            best_val = val_m[\"rmse\"]\n",
    "            best_epoch = epoch + 1\n",
    "            save_checkpoint(best_ckpt_path, best_epoch, best_val)\n",
    "            print(f\"  ↳ saved best checkpoint @ epoch {best_epoch} (val_RMSE={best_val:.4f})\")\n",
    "\n",
    "        # early stop check\n",
    "        if stopper.step(val_m[\"rmse\"]):\n",
    "            print(f\"Early stopping after {epoch+1} epochs (no improvement for {stopper.patience}).\")\n",
    "            break\n",
    "\n",
    "    print(f\"Best val_RMSE={best_val:.4f} at epoch {best_epoch}\")\n",
    "    print(f\"best: {best_ckpt_path}\\nlast: {last_ckpt_path}\")\n",
    "    return SimpleNamespace(best_val_rmse=best_val, best_epoch=best_epoch,\n",
    "                           best_path=best_ckpt_path, last_path=last_ckpt_path)\n",
    "\n",
    "# run training with checkpoints + early stop\n",
    "train_summary = train_with_ckpt(patience=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66fcb4ec1185c211",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T17:24:11.847866Z",
     "start_time": "2025-09-16T17:24:10.720901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best checkpoint: checkpoints\\20250916-202151\\best.ckpt\n",
      "missing: 0 unexpected: 0\n",
      "VAL  | TTA=True | RMSE=0.2148 | PLCC=0.8129\n",
      "Calib(linear): a=1.2423, b=-0.1961\n",
      "TEST | raw   | RMSE=0.2287 | PLCC=0.7954\n",
      "TEST | calib | RMSE=0.2579 | PLCC=0.7954\n"
     ]
    }
   ],
   "source": [
    "# CELL 12 — Restore best, Evaluate on VAL/TEST with TTA, optional linear calibration\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "@torch.no_grad()\n",
    "def _predict_loader(loader, tta: bool):\n",
    "    model.eval()\n",
    "    yh, yt = [], []\n",
    "    for batch in loader:\n",
    "        orig, mixed, delta, grads, y, w = _move_to_device(batch, cfg.device)\n",
    "\n",
    "        def _fwd(o, m, d, g):  # single pass\n",
    "            return model(o, m, d, g)\n",
    "\n",
    "        # base\n",
    "        y0 = _fwd(orig, mixed, delta, grads)\n",
    "\n",
    "        if not tta:\n",
    "            yh.append(y0.cpu())\n",
    "            yt.append(y.cpu())\n",
    "            continue\n",
    "\n",
    "        # TTA: hflip, vflip, hvflip (flip inputs only; scalar output)\n",
    "        y_list = [y0]\n",
    "        for dims in [(3,), (2,), (2, 3)]:\n",
    "            o = torch.flip(orig,  dims)\n",
    "            m = torch.flip(mixed, dims)\n",
    "            d = torch.flip(delta, dims)\n",
    "            g = torch.flip(grads, dims) if grads is not None else None\n",
    "            y_list.append(_fwd(o, m, d, g))\n",
    "        y_avg = torch.stack(y_list, dim=0).mean(dim=0)\n",
    "\n",
    "        yh.append(y_avg.cpu())\n",
    "        yt.append(y.cpu())\n",
    "\n",
    "    yhat = torch.cat(yh, 0).view(-1).numpy()\n",
    "    ytrue = torch.cat(yt, 0).view(-1).numpy()\n",
    "    return yhat, ytrue\n",
    "\n",
    "def _metrics_np(yhat, ytrue):\n",
    "    e = yhat - ytrue\n",
    "    rmse_ = float(np.sqrt(np.mean(e**2)))\n",
    "    x = yhat - yhat.mean()\n",
    "    t = ytrue - ytrue.mean()\n",
    "    denom = np.sqrt((x**2).mean() * (t**2).mean()) + 1e-8\n",
    "    plcc_ = float((x * t).mean() / denom)\n",
    "    return rmse_, plcc_\n",
    "\n",
    "# --- load best checkpoint ---\n",
    "ckpt_dir = cfg.checkpoints_dir / cfg.run_id\n",
    "state = torch.load(best_ckpt_path, map_location=cfg.device)\n",
    "res = model.load_state_dict(state[\"model\"], strict=False)\n",
    "print(f\"Loaded best checkpoint: {best_ckpt_path}\")\n",
    "print(\"missing:\", len(res.missing_keys), \"unexpected:\", len(res.unexpected_keys))\n",
    "\n",
    "\n",
    "# --- toggles ---\n",
    "use_tta = bool(getattr(getattr(cfg, \"push99\", type(\"X\",(object,),{})()), \"use_tta\", True))\n",
    "use_linear_calib = True  # small boost without heavy code; fits in this cell\n",
    "\n",
    "# --- VAL (no calib) ---\n",
    "yhat_v, y_v = _predict_loader(cfg.val_loader, tta=use_tta)\n",
    "rmse_v, plcc_v = _metrics_np(yhat_v, y_v)\n",
    "print(f\"VAL  | TTA={use_tta} | RMSE={rmse_v:.4f} | PLCC={plcc_v:.4f}\")\n",
    "\n",
    "# --- optional linear calibration on VAL, then apply to TEST ---\n",
    "if use_linear_calib:\n",
    "    # ŷ* = a·ŷ + b (least squares on VAL)\n",
    "    A = np.vstack([yhat_v, np.ones_like(yhat_v)]).T\n",
    "    a, b = np.linalg.lstsq(A, y_v, rcond=None)[0]\n",
    "    def _calib(x): return a * x + b\n",
    "    print(f\"Calib(linear): a={a:.4f}, b={b:.4f}\")\n",
    "else:\n",
    "    _calib = lambda x: x\n",
    "\n",
    "# --- TEST ---\n",
    "yhat_t, y_t = _predict_loader(cfg.test_loader, tta=use_tta)\n",
    "rmse_t, plcc_t = _metrics_np(yhat_t, y_t)\n",
    "print(f\"TEST | raw   | RMSE={rmse_t:.4f} | PLCC={plcc_t:.4f}\")\n",
    "\n",
    "if use_linear_calib:\n",
    "    yhat_t_c = _calib(yhat_t)\n",
    "    rmse_t_c, plcc_t_c = _metrics_np(yhat_t_c, y_t)\n",
    "    print(f\"TEST | calib | RMSE={rmse_t_c:.4f} | PLCC={plcc_t_c:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c41f10738955bbe4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T17:35:05.239813Z",
     "start_time": "2025-09-16T17:35:04.787175Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ONNX: C:\\Users\\YehonatanR\\OneDrive\\Documents\\HIT Computer Science\\3rd\\PixelQuality\\PythonProject\\artifacts\\model.onnx\n",
      "Saved TorchScript: C:\\Users\\YehonatanR\\OneDrive\\Documents\\HIT Computer Science\\3rd\\PixelQuality\\PythonProject\\artifacts\\model.ts.pt\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Export trained model to ONNX and TorchScript for Netron.\n",
    "Handles both variants: with or without a 'grads' input.\n",
    "Assumes `model` is defined and best weights are loaded.\n",
    "\"\"\"\n",
    "from pathlib import Path\n",
    "import inspect\n",
    "import torch\n",
    "\n",
    "model.eval()\n",
    "dev = next(model.parameters()).device\n",
    "\n",
    "ART = Path(\"artifacts\"); ART.mkdir(parents=True, exist_ok=True)\n",
    "onnx_path = ART / \"model.onnx\"\n",
    "ts_path   = ART / \"model.ts.pt\"\n",
    "\n",
    "# Detect whether the model expects a 'grads' tensor\n",
    "sig = inspect.signature(model.forward)\n",
    "expects_grads = (\"grads\" in sig.parameters) or bool(getattr(model, \"use_grads\", False))\n",
    "\n",
    "# Build dummy inputs: (N,C,H,W) = (1,3,20,20)\n",
    "B, C, H, W = 1, 3, 20, 20\n",
    "orig  = torch.randn(B, C, H, W, device=dev)\n",
    "mixed = torch.randn(B, C, H, W, device=dev)\n",
    "delta = torch.randn(B, C, H, W, device=dev)\n",
    "\n",
    "if expects_grads:\n",
    "    grads = torch.randn(B, C, H, W, device=dev)\n",
    "    dummy_args  = (orig, mixed, delta, grads)\n",
    "    input_names = [\"orig\", \"mixed\", \"delta\", \"grads\"]\n",
    "else:\n",
    "    dummy_args  = (orig, mixed, delta)\n",
    "    input_names = [\"orig\", \"mixed\", \"delta\"]\n",
    "\n",
    "# Sanity forward\n",
    "with torch.no_grad():\n",
    "    _ = model(*dummy_args)\n",
    "\n",
    "# ONNX export\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_args,\n",
    "    onnx_path.as_posix(),\n",
    "    input_names=input_names,\n",
    "    output_names=[\"logits\"],\n",
    "    opset_version=17,\n",
    "    do_constant_folding=True,\n",
    "    dynamic_axes={name: {0: \"batch\"} for name in input_names} | {\"logits\": {0: \"batch\"}},\n",
    ")\n",
    "print(\"Saved ONNX:\", onnx_path.resolve())\n",
    "\n",
    "# TorchScript (trace)\n",
    "ts = torch.jit.trace(model, dummy_args)\n",
    "ts.save(ts_path.as_posix())\n",
    "print(\"Saved TorchScript:\", ts_path.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "69ebbe0fe94efb5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T17:35:10.683890Z",
     "start_time": "2025-09-16T17:35:10.664735Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching Netron on port 8080...\n",
      "Netron not available. Install with: pip install netron\n",
      "Then open the exported file manually: C:\\Users\\YehonatanR\\OneDrive\\Documents\\HIT Computer Science\\3rd\\PixelQuality\\PythonProject\\artifacts\\model.onnx\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Open Netron viewer\n",
    "If running locally, this launches http://localhost:8080\n",
    "\"\"\"\n",
    "try:\n",
    "    import netron\n",
    "    print(\"Launching Netron on port 8080...\")\n",
    "    netron.start(onnx_path.as_posix(), address=\"127.0.0.1\", browse=True)\n",
    "except Exception as e:\n",
    "    print(\"Netron not available. Install with: pip install netron\")\n",
    "    print(\"Then open the exported file manually:\", onnx_path.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2305d9243268c3bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T17:24:12.307486500Z",
     "start_time": "2025-09-09T16:06:16.870442Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c113b449d3305e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T17:24:12.307486500Z",
     "start_time": "2025-09-09T16:06:16.885057Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b121918f268212c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T17:24:12.325402Z",
     "start_time": "2025-09-09T16:06:17.090669Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
