{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1vYK3xyy2_tnJeMo5_H5dK0cRKcqLCM0n","authorship_tag":"ABX9TyO4eAxYWxdN7R305CzHIgTR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Imports & Paths"],"metadata":{"id":"rg4quL9bxt5k"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"KjH56CBhl_aF","executionInfo":{"status":"ok","timestamp":1755000302134,"user_tz":-180,"elapsed":13708,"user":{"displayName":"Tomer Portal","userId":"10561052838046462936"}}},"outputs":[],"source":["from PIL import Image\n","from google.colab import userdata\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","try:\n","    from torchinfo import summary as info\n","except:\n","    !pip install torchinfo\n","    from torchinfo import summary as info\n","\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","import json\n","import os\n","\n","from IPython.core.magic import register_cell_magic\n","@register_cell_magic\n","def skip(line, cell):\n","    print(line)\n","    return\n","\n"]},{"cell_type":"code","source":["project_path = userdata.get('PATH_PROJECT')\n","dataset_path = os.path.join(project_path, 'dataset')\n","\n","train_path = os.path.join(dataset_path, 'train_metadata.json')\n","test_path = os.path.join(dataset_path, 'test_metadata.json')\n","\n","import sys\n","src_path = os.path.join(project_path, 'src')\n","sys.path.append(src_path)\n","\n"],"metadata":{"id":"Bm_oGrpNrdmy","executionInfo":{"status":"ok","timestamp":1755000302660,"user_tz":-180,"elapsed":523,"user":{"displayName":"Tomer Portal","userId":"10561052838046462936"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["# The Data & Dataset Class"],"metadata":{"id":"qUP9NvFNM4vZ"}},{"cell_type":"code","metadata":{"id":"ae487798","executionInfo":{"status":"ok","timestamp":1755000302946,"user_tz":-180,"elapsed":285,"user":{"displayName":"Tomer Portal","userId":"10561052838046462936"}},"colab":{"base_uri":"https://localhost:8080/","height":391},"outputId":"aeda3578-a5a8-406c-d2a3-ae38ad6d274d"},"source":["with open(train_path) as train, open(test_path) as test:\n","    train_samples = json.load(train)\n","    test_samples = json.load(test)\n","\n","# Get the scores for the training and testing sets\n","train_scores = [sample['score'] for sample in train_samples]\n","test_scores = [sample['score'] for sample in test_samples]\n","\n","# Calculate the distribution of scores\n","train_score_distribution = pd.Series(train_scores).value_counts().sort_index()\n","test_score_distribution = pd.Series(test_scores).value_counts().sort_index()\n","\n","# Display the distributions\n","print(\"Train set score distribution:\")\n","display(train_score_distribution)\n","\n","print(\"\\nTest set score distribution:\")\n","display(test_score_distribution)"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Train set score distribution:\n"]},{"output_type":"display_data","data":{"text/plain":["0.0    1594\n","0.5     497\n","1.0     867\n","Name: count, dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0.0</th>\n","      <td>1594</td>\n","    </tr>\n","    <tr>\n","      <th>0.5</th>\n","      <td>497</td>\n","    </tr>\n","    <tr>\n","      <th>1.0</th>\n","      <td>867</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Test set score distribution:\n"]},{"output_type":"display_data","data":{"text/plain":["0.0    389\n","0.5    127\n","1.0    224\n","Name: count, dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0.0</th>\n","      <td>389</td>\n","    </tr>\n","    <tr>\n","      <th>0.5</th>\n","      <td>127</td>\n","    </tr>\n","    <tr>\n","      <th>1.0</th>\n","      <td>224</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{}}]},{"cell_type":"code","source":["from PairedImageDataset import PairedImageDataset\n","\n","# Create dataset instances\n","train_dataset = PairedImageDataset(root_dir=dataset_path, metadata_json_path=train_path)\n","test_dataset = PairedImageDataset(root_dir=dataset_path, metadata_json_path=test_path)\n","\n","# Create dataloader instances\n","batch_size = 32\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=2)\n","test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True, num_workers=2)\n","\n","print(f\"Number of training samples: {len(train_dataset)}\")\n","print(f\"Number of testing samples: {len(test_dataset)}\")\n","print(f\"Batch size: {batch_size}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Oziwz5NowPMi","executionInfo":{"status":"ok","timestamp":1755001370876,"user_tz":-180,"elapsed":1715,"user":{"displayName":"Tomer Portal","userId":"10561052838046462936"}},"outputId":"a5b0e5c8-3695-4320-c9dc-4e3973cd3f41"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of training samples: 2958\n","Number of testing samples: 740\n","Batch size: 32\n"]}]},{"cell_type":"markdown","source":["# Model & Training"],"metadata":{"id":"Vze9yUveqpG-"}},{"cell_type":"markdown","source":["Stack two images togther (6 x 20 x 20) tensor.\n","No augmentations.\n","MSE loss.\n","Layers:\n","1. CNN [in=6, out=6, kernel=3]\n","2. CNN [in=6, out=3, kernel=1]\n","3. CNN [in=3, out=1, kernel=3]\n","4. Flatten\n","5. Linear Layer [..., 1]\n","6. Sigmoid\n"],"metadata":{"id":"_kLduZKVghKv"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":434},"id":"46eccbac","executionInfo":{"status":"ok","timestamp":1755000724436,"user_tz":-180,"elapsed":84,"user":{"displayName":"Tomer Portal","userId":"10561052838046462936"}},"outputId":"35d98b20-e1a4-459c-dce1-721b368354bc"},"source":["import torch\n","import torch.nn as nn\n","\n","class ImageComparisonModel(nn.Module):\n","    def __init__(self):\n","        super(ImageComparisonModel, self).__init__()\n","        self.cnn_layers = nn.Sequential(\n","            # Layer 1: CNN [in=6, out=6, kernel=3]\n","            nn.Conv2d(in_channels=6, out_channels=6, kernel_size=3, padding=1),\n","            nn.ReLU(), # Added ReLU activation\n","            # Layer 2: CNN [in=6, out=3, kernel=1]\n","            nn.Conv2d(in_channels=6, out_channels=3, kernel_size=1),\n","            nn.ReLU(), # Added ReLU activation\n","            # Layer 3: CNN [in=3, out=1, kernel=3]\n","            nn.Conv2d(in_channels=3, out_channels=1, kernel_size=3, padding=1),\n","            nn.ReLU() # Added ReLU activation\n","        )\n","        self.flatten = nn.Flatten()\n","        # Layer 5: Linear Layer [..., 3] - Output size changed to 3 for 3 classes\n","        self.linear_layer = nn.Linear(in_features=1*20*20, out_features=3) # Output features changed to 3\n","        # Removed Sigmoid activation for classification\n","        # self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, img_clean, img_other):\n","        # Stack images together: (batch_size, 6, H, W)\n","        combined_images = torch.cat((img_clean, img_other), dim=1)\n","\n","        # Pass through CNN layers\n","        cnn_output = self.cnn_layers(combined_images)\n","\n","        # Flatten the output\n","        flattened_output = self.flatten(cnn_output)\n","\n","        # Pass through linear layer\n","        linear_output = self.linear_layer(flattened_output)\n","\n","        # For classification, we return the raw logits\n","        # output = self.sigmoid(linear_output) # Removed Sigmoid\n","\n","        return linear_output # Return logits\n","\n","# Instantiate the model\n","model = ImageComparisonModel()\n","# Use torchinfo.summary for models with multiple inputs\n","display(info(model, input_size=[(1, 3, 20, 20), (1, 3, 20, 20)], device='cpu')) # Providing shapes for img_clean and img_other"],"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":["==========================================================================================\n","Layer (type:depth-idx)                   Output Shape              Param #\n","==========================================================================================\n","ImageComparisonModel                     [1, 3]                    --\n","├─Sequential: 1-1                        [1, 1, 20, 20]            --\n","│    └─Conv2d: 2-1                       [1, 6, 20, 20]            330\n","│    └─ReLU: 2-2                         [1, 6, 20, 20]            --\n","│    └─Conv2d: 2-3                       [1, 3, 20, 20]            21\n","│    └─ReLU: 2-4                         [1, 3, 20, 20]            --\n","│    └─Conv2d: 2-5                       [1, 1, 20, 20]            28\n","│    └─ReLU: 2-6                         [1, 1, 20, 20]            --\n","├─Flatten: 1-2                           [1, 400]                  --\n","├─Linear: 1-3                            [1, 3]                    1,203\n","==========================================================================================\n","Total params: 1,582\n","Trainable params: 1,582\n","Non-trainable params: 0\n","Total mult-adds (Units.MEGABYTES): 0.15\n","==========================================================================================\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 0.03\n","Params size (MB): 0.01\n","Estimated Total Size (MB): 0.05\n","=========================================================================================="]},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f3530992","executionInfo":{"status":"ok","timestamp":1755002800285,"user_tz":-180,"elapsed":45,"user":{"displayName":"Tomer Portal","userId":"10561052838046462936"}},"outputId":"89ec0c7c-26ec-4606-e2b3-462ed249f60f"},"source":["# Define the loss function (Cross Entropy for classification)\n","criterion = nn.CrossEntropyLoss()\n","\n","# Define the optimizer (Adam is a good general-purpose optimizer)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # You can adjust the learning rate as needed\n","\n","# Define the device: GPU if available, CPU otherwise\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","print(\"Loss function:\", criterion)\n","print(\"Optimizer:\", optimizer)\n","print(\"Device:\", device)"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Loss function: CrossEntropyLoss()\n","Optimizer: Adam (\n","Parameter Group 0\n","    amsgrad: False\n","    betas: (0.9, 0.999)\n","    capturable: False\n","    differentiable: False\n","    eps: 1e-08\n","    foreach: None\n","    fused: None\n","    lr: 0.001\n","    maximize: False\n","    weight_decay: 0\n",")\n","Device: cpu\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a38ea2d6","executionInfo":{"status":"ok","timestamp":1755002793790,"user_tz":-180,"elapsed":29909,"user":{"displayName":"Tomer Portal","userId":"10561052838046462936"}},"outputId":"3677f0e5-4dd6-42d6-d938-418fd170b60d"},"source":["# Get a batch from the test dataloader\n","img_clean, img_other, score = next(iter(test_dataloader))\n","\n","# Move data to the same device as the model (if using GPU)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)\n","img_clean = img_clean.to(device)\n","img_other = img_other.to(device)\n","\n","# Perform a forward pass\n","with torch.no_grad(): # No need to calculate gradients for a test pass\n","    output = model(img_clean, img_other)\n","\n","# Print the output shape and a few values\n","print(\"Model output shape:\", output.shape)\n","print(\"Sample model outputs:\", output[:5].squeeze()) # Print first 5 outputs\n","print(\"Sample true scores:\", score[:5]) # Print first 5 true scores"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Model output shape: torch.Size([32, 3])\n","Sample model outputs: tensor([[ 0.3117, -0.7287,  0.2347],\n","        [ 0.3340, -0.7710,  0.2255],\n","        [ 0.3359, -0.8154,  0.2127],\n","        [ 0.3274, -0.7857,  0.2190],\n","        [ 0.3171, -0.7453,  0.2213]])\n","Sample true scores: tensor([1, 0, 1, 2, 0])\n"]}]},{"cell_type":"markdown","source":["## Training loop"],"metadata":{"id":"2Tf68Xkvq49p"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":426},"id":"18728af7","executionInfo":{"status":"error","timestamp":1755004067208,"user_tz":-180,"elapsed":663858,"user":{"displayName":"Tomer Portal","userId":"10561052838046462936"}},"outputId":"e2eb012a-5d70-4afc-b647-9c22953620a8"},"source":["# Training loop\n","num_epochs = 10 # You can adjust the number of epochs\n","\n","# Set the model to training mode & Move the model to device\n","model.train()\n","model.to(device)\n","\n","for epoch in range(num_epochs):\n","    running_loss = 0.0\n","    correct_train_predictions = 0\n","    total_train_samples_epoch = 0\n","\n","    print(f\"Start Epoch [{epoch+1}/{num_epochs}]\")\n","\n","    # Iterate over the training data in batches\n","    for i, (img_clean, img_other, class_indices) in enumerate(train_dataloader):\n","        # Move batch data to the device, if not preloaded\n","        if not train_dataset.preload:\n","             img_clean = img_clean.to(device)\n","             img_other = img_other.to(device)\n","             class_indices = class_indices.to(device)\n","\n","        # Zero the gradients\n","        optimizer.zero_grad()\n","\n","        # Forward pass\n","        # Model outputs are now logits for each class: (batch_size, num_classes)\n","        outputs = model(img_clean, img_other)\n","\n","        # Calculate the loss\n","        # CrossEntropyLoss expects outputs to be (batch_size, num_classes) and targets to be (batch_size) with class indices (dtype=long)\n","        loss = criterion(outputs, class_indices.long()) # Ensure target class indices are long type\n","\n","        # Backward pass and optimize\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item() * img_clean.size(0) # Accumulate loss, weighted by batch size\n","        total_train_samples_epoch += img_clean.size(0)\n","\n","        # Calculate training accuracy for the batch\n","        # Get predicted class indices by taking the argmax of the outputs (logits)\n","        _, predicted_train_classes = torch.max(outputs, 1)\n","        correct_train_predictions += (predicted_train_classes == class_indices.long()).sum().item() # Ensure target class indices are long type\n","\n","    # Calculate average epoch loss and training accuracy\n","    epoch_loss = running_loss / total_train_samples_epoch\n","    train_accuracy = correct_train_predictions / total_train_samples_epoch\n","\n","\n","    # Print epoch loss and training accuracy\n","    print(f\"End Epoch [{epoch+1}/{num_epochs}]\")\n","    print(f\"Average Training Loss: {epoch_loss:.4f}\")\n","    print(f\"Training Accuracy: {train_accuracy:.4f}\")\n","\n","\n","    # Evaluation on test data (can still process in batches for memory efficiency)\n","    model.eval()\n","    test_loss = 0.0\n","    correct_test_predictions = 0\n","    total_test_samples_epoch = 0\n","\n","    with torch.no_grad():\n","        for img_clean, img_other, class_indices in test_dataloader:\n","             # Move batch data to the device, if not preloaded\n","             if not test_dataset.preload:\n","                 img_clean = img_clean.to(device)\n","                 img_other = img_other.to(device)\n","                 class_indices = class_indices.to(device)\n","\n","             test_outputs = model(img_clean, img_other)\n","             test_loss += criterion(test_outputs, class_indices.long()).item() * img_clean.size(0) # Accumulate loss\n","\n","             # Calculate test accuracy for the batch\n","             _, predicted_test_classes = torch.max(test_outputs, 1)\n","             correct_test_predictions += (predicted_test_classes == class_indices.long()).sum().item() # Ensure target class indices are long type\n","             total_test_samples_epoch += img_clean.size(0)\n","\n","    # Calculate average test loss and accuracy\n","    test_loss /= total_test_samples_epoch\n","    test_accuracy = correct_test_predictions / total_test_samples_epoch\n","\n","    print(f\"Test Loss: {test_loss:.4f}\")\n","    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n","\n","\n","print(\"Training finished!\")"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Start Epoch [1/10]\n","End Epoch [1/10]\n","Average Training Loss: 1.0030\n","Training Accuracy: 0.5377\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2882200726.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimg_clean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_other\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_indices\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m              \u001b[0;31m# Move batch data to the device, if not preloaded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m              \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1459\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1419\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1421\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["## Save the model"],"metadata":{"id":"WpSE3UrGxpLC"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f5a3ef40","executionInfo":{"status":"ok","timestamp":1754682676148,"user_tz":-180,"elapsed":79,"user":{"displayName":"Tomer Portal","userId":"10561052838046462936"}},"outputId":"77dccc95-6adc-412f-8ffa-42a663b1c655"},"source":["%%skip Comment out skip to save the model\n","\n","# Define the path to save the model\n","model_save_path = os.path.join(project_path, 'src/image_comparison_model.pth')\n","\n","# Save the model's state dictionary\n","torch.save(model.state_dict(), model_save_path)\n","\n","print(f\"Model saved to: {model_save_path}\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model saved to: /content/drive/MyDrive/Colab Notebooks/Samsung/image_comparison_model.pth\n"]}]},{"cell_type":"markdown","metadata":{"id":"22fe90da"},"source":["# Evaluation\n","Compute the confusion matrix for the test set predictions and true scores, using the bins [0-0.3, 0.3-0.6, 0.6-1] and the labels [RED, ORANGE, GREEN]."]},{"cell_type":"markdown","metadata":{"id":"aef96844"},"source":["## Run inference on the test set\n","\n","Use the trained model to get predictions for all samples in the test dataset.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f3516785","executionInfo":{"status":"ok","timestamp":1755004572968,"user_tz":-180,"elapsed":59412,"user":{"displayName":"Tomer Portal","userId":"10561052838046462936"}},"outputId":"a0dc5328-836a-4e18-ed8c-ee16952cd7dd"},"source":["# Set the model to evaluation mode\n","model.eval()\n","\n","# Disable gradient calculation\n","with torch.no_grad():\n","    # Get predictions for the test set by iterating through the test_dataloader\n","    all_test_outputs = []\n","    all_test_class_indices = [] # Store true class indices for evaluation\n","\n","    for img_clean, img_other, class_indices in test_dataloader:\n","        # Move batch data to the device (if not preloaded)\n","        if not test_dataset.preload:\n","            img_clean = img_clean.to(device)\n","            img_other = img_other.to(device)\n","            class_indices = class_indices.to(device)\n","\n","        test_outputs = model(img_clean, img_other)\n","        all_test_outputs.append(test_outputs.cpu()) # Move to CPU for concatenation and later processing\n","        all_test_class_indices.append(class_indices.cpu()) # Move true indices to CPU\n","\n","    # Concatenate all batch outputs and true class indices\n","    all_test_outputs = torch.cat(all_test_outputs, dim=0)\n","    all_test_class_indices = torch.cat(all_test_class_indices, dim=0)\n","\n","\n","print(\"All test outputs shape:\", all_test_outputs.shape)\n","print(\"All true test class indices shape:\", all_test_class_indices.shape)\n","print(\"Sample test outputs (logits):\", all_test_outputs[:5].squeeze())\n","print(\"Sample true test class indices:\", all_test_class_indices[:5])"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["All test outputs shape: torch.Size([736, 3])\n","All true test class indices shape: torch.Size([736])\n","Sample test outputs (logits): tensor([[ 0.4209, -0.6457, -0.0028],\n","        [ 0.4594, -0.6999, -0.0161],\n","        [ 0.4865, -0.7750, -0.0368],\n","        [ 0.4605, -0.7308, -0.0251],\n","        [ 0.4306, -0.6641, -0.0158]])\n","Sample true test class indices: tensor([1, 0, 1, 2, 0])\n"]}]},{"cell_type":"markdown","metadata":{"id":"50d1dbbf"},"source":["## Digitize predictions\n","\n","Convert the continuous model outputs into discrete labels (bins [0-0.3, 0.3-0.6, 0.6-1]).\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"522f6f0f","executionInfo":{"status":"ok","timestamp":1755004661690,"user_tz":-180,"elapsed":22,"user":{"displayName":"Tomer Portal","userId":"10561052838046462936"}},"outputId":"ab852f23-0703-406f-e34f-4ee641d23920"},"source":["# Get predicted class indices by taking the argmax of the logits\n","# The argmax along dimension 1 gives the index of the maximum logit for each sample in the batch\n","predicted_test_class_indices = torch.argmax(all_test_outputs, dim=1)\n","\n","# Convert indices to labels if needed for clarity in some metrics, but indices are fine for confusion matrix and most metrics\n","labels = ['RED', 'ORANGE', 'GREEN']\n","predicted_test_labels = [labels[i] for i in predicted_test_class_indices.tolist()]\n","\n","\n","print(\"Predicted test class indices shape:\", predicted_test_class_indices.shape)\n","print(\"Sample predicted test class indices:\", predicted_test_class_indices[:5])\n","print(\"Sample predicted test labels:\", predicted_test_labels[:5])"],"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted test class indices shape: torch.Size([736])\n","Sample predicted test class indices: tensor([0, 0, 0, 0, 0])\n","Sample predicted test labels: ['RED', 'RED', 'RED', 'RED', 'RED']\n"]}]},{"cell_type":"markdown","metadata":{"id":"c9f21ea0"},"source":["## Digitize true scores\n","\n","Convert the continuous true scores from the test set into the same discrete labels using the same bins.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"199942b4","executionInfo":{"status":"ok","timestamp":1755004664612,"user_tz":-180,"elapsed":32,"user":{"displayName":"Tomer Portal","userId":"10561052838046462936"}},"outputId":"035ac783-a2d0-4ced-b017-af764479d759"},"source":["# The true test class indices are already stored in all_test_class_indices\n","# which were collected during the inference step.\n","\n","# Convert true indices to labels if needed for clarity\n","labels = ['RED', 'ORANGE', 'GREEN']\n","true_test_labels = [labels[i] for i in all_test_class_indices.tolist()]\n","\n","print(\"True test class indices shape:\", all_test_class_indices.shape)\n","print(\"Sample true test class indices:\", all_test_class_indices[:5])\n","print(\"Sample true test labels:\", true_test_labels[:5])"],"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["True test class indices shape: torch.Size([736])\n","Sample true test class indices: tensor([1, 0, 1, 2, 0])\n","Sample true test labels: ['ORANGE', 'RED', 'ORANGE', 'GREEN', 'RED']\n"]}]},{"cell_type":"markdown","metadata":{"id":"479eba2a"},"source":["## Compute the confusion matrix\n","\n","Calculate the confusion matrix comparing the digitized predictions and the digitized true scores.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cf867889","executionInfo":{"status":"ok","timestamp":1755004666985,"user_tz":-180,"elapsed":8,"user":{"displayName":"Tomer Portal","userId":"10561052838046462936"}},"outputId":"5420232f-4aab-4031-f18e-ca1405d27542"},"source":["from sklearn.metrics import confusion_matrix\n","\n","# Compute the confusion matrix\n","# confusion_matrix expects true labels first, then predicted labels\n","# Use the class indices directly, as sklearn's confusion_matrix works with numerical labels\n","conf_matrix = confusion_matrix(all_test_class_indices.numpy(), predicted_test_class_indices.numpy(), labels=[0, 1, 2])\n","\n","# Print the confusion matrix\n","print(\"Confusion Matrix (Labels: 0=RED, 1=ORANGE, 2=GREEN):\")\n","print(conf_matrix)"],"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Confusion Matrix (Labels: 0=RED, 1=ORANGE, 2=GREEN):\n","[[387   0   0]\n"," [125   0   0]\n"," [224   0   0]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"c6776b96"},"source":["## Display the confusion matrix\n","\n","Present the confusion matrix, potentially with labels [RED, ORANGE, GREEN] corresponding to the bins.\n","\n","Using `ConfusionMatrixDisplay`."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":588},"id":"105243d1","executionInfo":{"status":"ok","timestamp":1755004671571,"user_tz":-180,"elapsed":172,"user":{"displayName":"Tomer Portal","userId":"10561052838046462936"}},"outputId":"794b3d7b-3930-4e27-8018-04f73f2ee878"},"source":["from sklearn.metrics import accuracy_score, precision_recall_fscore_support, ConfusionMatrixDisplay\n","import matplotlib.pyplot as plt\n","\n","# Calculate accuracy\n","accuracy = accuracy_score(all_test_class_indices.numpy(), predicted_test_class_indices.numpy())\n","\n","# Define labels for metrics and display\n","labels_names = ['RED', 'ORANGE', 'GREEN']\n","labels_indices = [0, 1, 2]\n","\n","# Calculate precision, recall, and F1-score (micro and macro)\n","# We need to specify the labels and zero_division to handle cases with no predictions\n","precision_micro, recall_micro, fscore_micro, _ = precision_recall_fscore_support(\n","    all_test_class_indices.numpy(), predicted_test_class_indices.numpy(), average='micro', labels=labels_indices, zero_division=0\n",")\n","precision_macro, recall_macro, fscore_macro, _ = precision_recall_fscore_support(\n","    all_test_class_indices.numpy(), predicted_test_class_indices.numpy(), average='macro', labels=labels_indices, zero_division=0\n",")\n","# Also calculate per-class metrics for more detail\n","precision_per_class, recall_per_class, fscore_per_class, support_per_class = precision_recall_fscore_support(\n","    all_test_class_indices.numpy(), predicted_test_class_indices.numpy(), labels=labels_indices, zero_division=0\n",")\n","\n","\n","print(f\"Model Accuracy: {accuracy:.4f}\")\n","print(f\"Micro Precision: {precision_micro:.4f}, Micro Recall: {recall_micro:.4f}, Micro F1 Score: {fscore_micro:.4f}\")\n","print(f\"Macro Precision: {precision_macro:.4f}, Macro Recall: {recall_macro:.4f}, Macro F1 Score: {fscore_macro:.4f}\")\n","print(\"\\nPer-Class Metrics:\")\n","for i, label_name in enumerate(labels_names):\n","    print(f\"  {label_name}:   Precision={precision_per_class[i]:.4f}, Recall={recall_per_class[i]:.4f}, F1 Score={fscore_per_class[i]:.4f}, Support={support_per_class[i]}\")\n","\n","\n","# Create a display object for the confusion matrix\n","cmd = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=labels_names)\n","\n","# Plot the confusion matrix\n","cmd.plot()\n","\n","# Display the plot\n","plt.show()"],"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Model Accuracy: 0.5258\n","Micro Precision: 0.5258, Micro Recall: 0.5258, Micro F1 Score: 0.5258\n","Macro Precision: 0.1753, Macro Recall: 0.3333, Macro F1 Score: 0.2297\n","\n","Per-Class Metrics:\n","  RED:   Precision=0.5258, Recall=1.0000, F1 Score=0.6892, Support=387\n","  ORANGE:   Precision=0.0000, Recall=0.0000, F1 Score=0.0000, Support=125\n","  GREEN:   Precision=0.0000, Recall=0.0000, F1 Score=0.0000, Support=224\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 2 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"1fcac566"},"source":["## Summary:\n","\n","### Data Analysis Key Findings\n","\n","* The model consistently predicted the 'ORANGE' category for all test samples, regardless of their true score bin.\n","* The confusion matrix shows that 389 samples with a true score in the [0-0.3) 'RED' bin were predicted as 'ORANGE'.\n","* 127 samples with a true score in the [0.3-0.6) 'ORANGE' bin were correctly predicted as 'ORANGE'.\n","* 224 samples with a true score in the [0.6-1] 'GREEN' bin were predicted as 'ORANGE'.\n","* The overall accuracy is low (0.1716), as the model is only correct when the true label is 'ORANGE'.\n","* The precision, recall, and F1 scores (both micro and macro) are heavily impacted by the model's tendency to only predict 'ORANGE'. The per-class metrics clearly show 0 precision and recall for the 'RED' and 'GREEN' classes.\n","\n","### Insights or Next Steps\n","\n","* The model's predictions are heavily skewed towards the 'ORANGE' category, indicating a potential issue with the model's ability to distinguish between the different score bins.\n","* Investigate the model architecture, training data, and loss function to understand why it is predominantly predicting 'ORANGE'. Consider re-training the model with a focus on improving performance across all score ranges. This might involve:\n","    * **Adjusting the loss function:** While MSE is used, explore if other loss functions like cross-entropy (if treating this as a classification problem after binning) or a custom loss function could be more effective.\n","    * **Modifying the model architecture:** The current model is quite simple. Consider adding more layers, different types of layers (e.g., pooling), or a more complex architecture.\n","    * **Data Augmentation:** While no augmentations were used, adding relevant data augmentations could help the model generalize better.\n","    * **Hyperparameter Tuning:** Experiment with different learning rates, optimizer settings, and number of training epochs.\n","    * **Class Imbalance:** Check if there's a significant imbalance in the number of samples in each score bin in the training data, and consider techniques to address class imbalance if necessary."]},{"cell_type":"markdown","metadata":{"id":"1a894331"},"source":["## Get predicted class indices\n","\n","Convert the model's output (logits) into predicted class indices."]},{"cell_type":"markdown","metadata":{"id":"5363b0d2"},"source":["## True class indices\n","\n","Use the true class indices obtained during data loading for evaluation."]},{"cell_type":"markdown","metadata":{"id":"c2576e7f"},"source":["## Compute the confusion matrix\n","\n","Calculate the confusion matrix comparing the predicted class indices and the true class indices."]},{"cell_type":"markdown","metadata":{"id":"9011ea57"},"source":["## Display the confusion matrix and classification metrics\n","\n","Present the confusion matrix and calculate/display other relevant classification metrics like accuracy, precision, recall, and F1-score.\n","\n","Using `ConfusionMatrixDisplay`."]},{"cell_type":"markdown","metadata":{"id":"f1fe2782"},"source":["## Summary:\n","\n","### Data Analysis Key Findings\n","\n","* Analyze the confusion matrix and the classification metrics (accuracy, precision, recall, F1-score) to understand how well the model performs on each class (RED, ORANGE, GREEN).\n","* Compare the performance across different classes to identify any class imbalance issues or difficulties in classifying specific classes.\n","\n","### Insights or Next Steps\n","\n","* Based on the evaluation metrics, assess the model's overall effectiveness in classifying the images into the three score bins.\n","* If the performance is not satisfactory, revisit the previous steps in the plan:\n","    * **Model Architecture:** Consider more complex or different CNN architectures.\n","    * **Hyperparameter Tuning:** Experiment with learning rates, optimizers, epoch count, etc.\n","    * **Data Augmentation:** Introduce data augmentation in the dataset if not already used.\n","    * **Class Imbalance:** If class distribution is uneven, explore techniques to handle it (e.g., weighted loss, resampling).\n","    * **Loss Function:** While CrossEntropyLoss is standard, investigate if variations or other loss functions might be more effective.\n","* If performance is reasonable, consider saving the trained model and potentially deploying it for inference on new data."]}]}