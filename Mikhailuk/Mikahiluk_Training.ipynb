{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a7ea831"
      },
      "source": [
        "## Load and split data\n",
        "\n",
        "### Subtask:\n",
        "Load the metadata from the JSON file and split it into training and testing sets. Save the split metadata into `train.json` and `test.json`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa526f7b"
      },
      "source": [
        "**Reasoning**:\n",
        "Import necessary libraries, load the metadata, split it into training and testing sets, and save the splits to separate JSON files.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g42rkqQlc99B"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import json\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2Yj0LHpc-fv",
        "outputId": "5d59eeab-ecb8-4cc8-fc0a-d670ec487743"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Selecting previously unselected package pv.\n",
            "(Reading database ... 126380 files and directories currently installed.)\n",
            "Preparing to unpack .../pv_1.6.6-1build2_amd64.deb ...\n",
            "Unpacking pv (1.6.6-1build2) ...\n",
            "Setting up pv (1.6.6-1build2) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Install pv for progress visualization\n",
        "!apt-get -qq install pv\n",
        "\n",
        "DATASET_PATH = \"/content/drive/MyDrive/Samsung_Project/tid2013\"\n",
        "REF_PATH = os.path.join(DATASET_PATH, \"reference_images\")\n",
        "DIST_PATH = os.path.join(DATASET_PATH, \"distorted_images\")\n",
        "MOS_FILE = os.path.join(DATASET_PATH, \"mos_with_names.txt\")\n",
        "PATCHES_PATH = \"/content/drive/MyDrive/Samsung_Project/tid2013_patches\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4tuFNXfEjgB"
      },
      "source": [
        "# Sanity check on dataset and patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xd7mURwvdADI",
        "outputId": "0516178a-394b-43ef-ec80-07bed370757e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset directory '/content/drive/MyDrive/Samsung_Project/tid2013' exists and contains files.\n",
            "Reference images directory '/content/drive/MyDrive/Samsung_Project/tid2013/reference_images' exists and contains files.\n",
            "Distorted images directory '/content/drive/MyDrive/Samsung_Project/tid2013/distorted_images' exists and contains files.\n",
            "MOS file '/content/drive/MyDrive/Samsung_Project/tid2013/mos_with_names.txt' found.\n",
            "Patches directory '/content/drive/MyDrive/Samsung_Project/tid2013_patches' exists.\n",
            "\n",
            "Sample reference image files:\n",
            "['I20.BMP', 'I23.BMP', 'I22.BMP', 'I04.BMP', 'I11.BMP']\n",
            "\n",
            "Sample distorted image files:\n",
            "['i06_23_3.bmp', 'i20_06_3.bmp', 'i18_02_3.bmp', 'i12_06_1.bmp', 'i22_19_4.bmp']\n",
            "\n",
            "Sample patch files from /content/drive/MyDrive/Samsung_Project/tid2013_patches/copy:\n",
            "['copy_patch_1283.png', 'copy_patch_0939.png', 'copy_patch_0866.png', 'copy_patch_1697.png', 'copy_patch_1928.png']\n",
            "\n",
            "Sample lines from MOS file:\n",
            "5.51429 I01_01_1.bmp\n",
            "5.56757 i01_01_2.bmp\n",
            "4.94444 i01_01_3.bmp\n",
            "4.37838 i01_01_4.bmp\n",
            "3.86486 i01_01_5.bmp\n"
          ]
        }
      ],
      "source": [
        "# Check if the dataset directory exists and contains files\n",
        "if os.path.exists(DATASET_PATH) and os.listdir(DATASET_PATH):\n",
        "    print(f\"Dataset directory '{DATASET_PATH}' exists and contains files.\")\n",
        "else:\n",
        "    print(f\"Error: Dataset directory '{DATASET_PATH}' not found or empty.\")\n",
        "\n",
        "# Check if reference and distorted image directories exist and contain files\n",
        "if os.path.exists(REF_PATH) and os.listdir(REF_PATH):\n",
        "    print(f\"Reference images directory '{REF_PATH}' exists and contains files.\")\n",
        "else:\n",
        "    print(f\"Error: Reference images directory '{REF_PATH}' not found or empty.\")\n",
        "\n",
        "if os.path.exists(DIST_PATH) and os.listdir(DIST_PATH):\n",
        "    print(f\"Distorted images directory '{DIST_PATH}' exists and contains files.\")\n",
        "else:\n",
        "    print(f\"Error: Distorted images directory '{DIST_PATH}' not found or empty.\")\n",
        "\n",
        "# Check if MOS file exists\n",
        "if os.path.exists(MOS_FILE):\n",
        "    print(f\"MOS file '{MOS_FILE}' found.\")\n",
        "else:\n",
        "    print(f\"Error: MOS file '{MOS_FILE}' not found.\")\n",
        "\n",
        "# Check if patches directory exists (it will be created later, so this is just a check)\n",
        "if os.path.exists(PATCHES_PATH):\n",
        "    print(f\"Patches directory '{PATCHES_PATH}' exists.\")\n",
        "else:\n",
        "    print(f\"Patches directory '{PATCHES_PATH}' does not exist\")\n",
        "\n",
        "# Optional: Display a few image file names to confirm data is there\n",
        "if os.path.exists(REF_PATH) and os.listdir(REF_PATH):\n",
        "    print(\"\\nSample reference image files:\")\n",
        "    print(random.sample(os.listdir(REF_PATH), min(5, len(os.listdir(REF_PATH)))))\n",
        "\n",
        "if os.path.exists(DIST_PATH) and os.listdir(DIST_PATH):\n",
        "    print(\"\\nSample distorted image files:\")\n",
        "    print(random.sample(os.listdir(DIST_PATH), min(5, len(os.listdir(DIST_PATH)))))\n",
        "\n",
        "# Display a few image file names from tid2013_patches/copy\n",
        "COPY_PATCHES_PATH = os.path.join(PATCHES_PATH, \"copy\")\n",
        "if os.path.exists(COPY_PATCHES_PATH) and os.listdir(COPY_PATCHES_PATH):\n",
        "    print(f\"\\nSample patch files from {COPY_PATCHES_PATH}:\")\n",
        "    print(random.sample(os.listdir(COPY_PATCHES_PATH), min(5, len(os.listdir(COPY_PATCHES_PATH)))))\n",
        "elif os.path.exists(COPY_PATCHES_PATH):\n",
        "     print(f\"\\nDirectory '{COPY_PATCHES_PATH}' is empty.\")\n",
        "else:\n",
        "    print(f\"\\nDirectory '{COPY_PATCHES_PATH}' does not exist.\")\n",
        "\n",
        "# Optional: Read a few lines of the MOS file\n",
        "if os.path.exists(MOS_FILE):\n",
        "    print(\"\\nSample lines from MOS file:\")\n",
        "    with open(MOS_FILE, 'r') as f:\n",
        "        for i, line in enumerate(f):\n",
        "            print(line.strip())\n",
        "            if i >= 4: # Print first 5 lines\n",
        "                break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jjvkowcaoSI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ac6f8d8-3b4b-43c9-8cd0-2c82fe2c68dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train metadata saved to: /content/drive/MyDrive/Samsung_Project/tid2013_patches/train.json\n",
            "Test metadata saved to: /content/drive/MyDrive/Samsung_Project/tid2013_patches/test.json\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "\n",
        "# Load the metadata from the patches directory\n",
        "# Corrected path to look directly in PATCHES_PATH\n",
        "metadata_path = os.path.join(PATCHES_PATH, \"metadata.json\")\n",
        "with open(metadata_path, 'r') as f:\n",
        "    metadata = json.load(f)\n",
        "\n",
        "# Extract data points - assuming metadata is a list\n",
        "data_points = metadata\n",
        "\n",
        "# Split data points into training and testing sets\n",
        "train_data, test_data = train_test_split(data_points, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create dictionaries for training and testing sets\n",
        "train_metadata = {'data': train_data}\n",
        "test_metadata = {'data': test_data}\n",
        "\n",
        "# Define the output paths for the split metadata files within the patches directory\n",
        "# Corrected paths to save directly in PATCHES_PATH\n",
        "train_json_path = os.path.join(PATCHES_PATH, \"train.json\")\n",
        "test_json_path = os.path.join(PATCHES_PATH, \"test.json\")\n",
        "\n",
        "# Save training metadata to train.json in the patches directory\n",
        "with open(train_json_path, 'w') as f:\n",
        "    json.dump(train_metadata, f, indent=4)\n",
        "\n",
        "# Save testing metadata to test.json in the patches directory\n",
        "with open(test_json_path, 'w') as f:\n",
        "    json.dump(test_metadata, f, indent=4)\n",
        "\n",
        "print(f\"Train metadata saved to: {train_json_path}\")\n",
        "print(f\"Test metadata saved to: {test_json_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bdae31e"
      },
      "source": [
        "## Implement dataset loader\n",
        "\n",
        "### Subtask:\n",
        "Create a custom dataset loader that reads the image pairs and scores from the split metadata files.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40fee55a"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement the custom dataset class including the `__init__`, `__len__`, and `__getitem__` methods to load and process image pairs and scores from the metadata.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6a641e4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03ff3b1a-d995-4c46-ae11-e1b977726cf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples: 1600\n",
            "Number of testing samples: 400\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import os\n",
        "import json\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "class ImagePairDataset(Dataset):\n",
        "    def __init__(self, metadata_file, img_dir):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            metadata_file (string): Path to the json file with annotations.\n",
        "            img_dir (string): Directory with all the images.\n",
        "        \"\"\"\n",
        "        with open(metadata_file, 'r') as f:\n",
        "            self.metadata = json.load(f)['data']\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Grayscale(num_output_channels=1),\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.metadata)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        img_info = self.metadata[idx]\n",
        "        ref_img_name = img_info['reference_image']\n",
        "        dist_img_name = img_info['distorted_image']\n",
        "        score = img_info['score']\n",
        "\n",
        "        ref_img_path = os.path.join(self.img_dir, ref_img_name)\n",
        "        dist_img_path = os.path.join(self.img_dir, dist_img_name)\n",
        "\n",
        "        ref_image = Image.open(ref_img_path)\n",
        "        dist_image = Image.open(dist_img_path)\n",
        "\n",
        "        # Apply transformations\n",
        "        ref_image = self.transform(ref_image)\n",
        "        dist_image = self.transform(dist_image)\n",
        "\n",
        "        return ref_image, dist_image, score\n",
        "\n",
        "# Example usage (optional, for testing the dataset class)\n",
        "train_dataset = ImagePairDataset(metadata_file=os.path.join(PATCHES_PATH, 'train.json'), img_dir='/content/drive/MyDrive/Samsung_Project/tid2013_patches/copy')\n",
        "test_dataset = ImagePairDataset(metadata_file=os.path.join(PATCHES_PATH, 'test.json'), img_dir='/content/drive/MyDrive/Samsung_Project/tid2013_patches/copy')\n",
        "\n",
        "print(f\"Number of training samples: {len(train_dataset)}\")\n",
        "print(f\"Number of testing samples: {len(test_dataset)}\")\n",
        "\n",
        "# sample_ref, sample_dist, sample_score = train_dataset[0]\n",
        "# print(f\"Sample reference image shape: {sample_ref.shape}\")\n",
        "# print(f\"Sample distorted image shape: {sample_dist.shape}\")\n",
        "# print(f\"Sample score: {sample_score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0644c162"
      },
      "source": [
        "## Implement the model\n",
        "\n",
        "### Subtask:\n",
        "Define the CNN model architecture as described in the prompt.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dea6f375"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the CNN model class with the specified architecture, including convolutional layers, flattening, a linear layer, and a sigmoid activation function.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-2ET7Tuqo0z"
      },
      "source": [
        "# PatchDiff-GAP (20×20) – 9-ch CNN Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pLYWs2na-gb",
        "outputId": "0418b811-0d97-4466-cbce-2e4641fff438"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model architecture:\n",
            "TinyPatchRegressor(\n",
            "  (conv1): Conv2d(6, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (n1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
            "  (conv2): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (n2): GroupNorm(4, 16, eps=1e-05, affine=True)\n",
            "  (conv3): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (gap): AdaptiveAvgPool2d(output_size=1)\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (fc): Linear(in_features=8, out_features=1, bias=True)\n",
            ")\n",
            "\n",
            "Starting training for 15 epochs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2756224355.py:167: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n",
            "/tmp/ipython-input-2756224355.py:181: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15, Loss: 0.0359\n",
            "Epoch 2/15, Loss: 0.0253\n",
            "Epoch 3/15, Loss: 0.0241\n",
            "Epoch 4/15, Loss: 0.0236\n",
            "Epoch 5/15, Loss: 0.0225\n",
            "Epoch 6/15, Loss: 0.0215\n",
            "Epoch 7/15, Loss: 0.0204\n",
            "Epoch 8/15, Loss: 0.0191\n",
            "Epoch 9/15, Loss: 0.0177\n",
            "Epoch 10/15, Loss: 0.0182\n",
            "Epoch 11/15, Loss: 0.0168\n",
            "Epoch 12/15, Loss: 0.0163\n",
            "Epoch 13/15, Loss: 0.0152\n",
            "Epoch 14/15, Loss: 0.0156\n",
            "Epoch 15/15, Loss: 0.0151\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import os\n",
        "import json\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define hyperparameters (add these lines)\n",
        "batch_size = 16 # Reduced batch size\n",
        "learning_rate = 0.001\n",
        "num_epochs = 15 # Increased epochs slightly to compensate for smaller batch size, but early stopping will prevent overfitting\n",
        "patience = 5 # Increased patience for early stopping\n",
        "min_delta = 0.0005 # Reduced minimum delta for early stopping\n",
        "\n",
        "# Updated ImagePairDatasetPatches to load distorted patches and generate reference patches on the fly\n",
        "class ImagePairDatasetPatches(Dataset):\n",
        "    def __init__(self, metadata_file, patch_dir, ref_img_original_dir):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            metadata_file (string): Path to the json file with annotations.\n",
        "            patch_dir (string): Directory with all the distorted patches (unique_sample_id).\n",
        "            ref_img_original_dir (string): Directory with original reference images (clean_image).\n",
        "        \"\"\"\n",
        "        with open(metadata_file, 'r') as f:\n",
        "            self.metadata = json.load(f)['data'] # Assuming the data is under the 'data' key\n",
        "        self.patch_dir = patch_dir\n",
        "        self.ref_img_original_dir = ref_img_original_dir\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToTensor(), # Keep as RGB (3 channels)\n",
        "        ])\n",
        "        # Create a case-insensitive mapping of filenames in the reference directory\n",
        "        self.ref_filenames_lower = {filename.lower(): filename for filename in os.listdir(ref_img_original_dir)}\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.metadata)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        img_info = self.metadata[idx]\n",
        "        try:\n",
        "            patch_filename = img_info['unique_sample_id']\n",
        "            original_ref_img_name = img_info['clean_image']\n",
        "            roi = img_info['metadata']['roi'] # Assuming roi is nested under 'metadata'\n",
        "            score = img_info['score']\n",
        "        except KeyError as e:\n",
        "            print(f\"KeyError: {e}. Available keys in metadata entry: {img_info.keys()}\")\n",
        "            if 'metadata' in img_info and 'roi' not in img_info['metadata']:\n",
        "                 print(f\"KeyError: 'roi' not found in metadata['metadata']. Available keys in 'metadata': {img_info['metadata'].keys()}\")\n",
        "            raise # Re-raise the exception after printing keys\n",
        "        except Exception as e:\n",
        "            print(f\"An unexpected error occurred while accessing metadata for index {idx}: {e}\")\n",
        "            raise\n",
        "\n",
        "\n",
        "        # Construct path to the distorted patch file\n",
        "        dist_patch_path = os.path.join(self.patch_dir, patch_filename)\n",
        "\n",
        "        # Construct path to the original reference image using case-insensitive lookup\n",
        "        original_ref_img_name_lower_from_metadata = original_ref_img_name.lower()\n",
        "        if original_ref_img_name_lower_from_metadata in self.ref_filenames_lower:\n",
        "            actual_ref_img_name = self.ref_filenames_lower[original_ref_img_name_lower_from_metadata]\n",
        "            original_ref_img_path = os.path.join(self.ref_img_original_dir, actual_ref_img_name)\n",
        "        else:\n",
        "            # If the file is not found even with case-insensitive lookup, raise an error\n",
        "            raise FileNotFoundError(f\"Original reference image '{original_ref_img_name}' (case-insensitive) not found in directory '{self.ref_img_original_dir}'.\")\n",
        "\n",
        "\n",
        "        try:\n",
        "            # Load the distorted patch\n",
        "            dist_patch = Image.open(dist_patch_path).convert('RGB') # Ensure RGB\n",
        "            original_ref_img = Image.open(original_ref_img_path).convert('RGB')\n",
        "            ref_patch = original_ref_img.crop((roi[0], roi[1], roi[0] + roi[2], roi[1] + roi[3]))\n",
        "\n",
        "\n",
        "        except FileNotFoundError as e:\n",
        "            print(f\"FileNotFoundError: Could not find image file. Details: {e}\")\n",
        "            print(f\"Attempted paths: Distorted patch: {dist_patch_path}, Original reference image: {original_ref_img_path}\")\n",
        "            raise\n",
        "        except IndexError:\n",
        "             print(f\"IndexError: Invalid ROI format for entry {idx}. ROI: {roi}\")\n",
        "             raise\n",
        "        except Exception as e:\n",
        "            print(f\"An unexpected error occurred while loading/processing images for index {idx}: {e}\")\n",
        "            print(f\"Attempted paths: Distorted patch: {dist_patch_path}, Original reference image: {original_ref_img_path}\")\n",
        "            raise\n",
        "\n",
        "\n",
        "        # Apply transformations\n",
        "        ref_patch = self.transform(ref_patch)\n",
        "        dist_patch = self.transform(dist_patch)\n",
        "\n",
        "        # Stack the reference and distorted patches along the channel dimension\n",
        "        stacked_patches = torch.cat([ref_patch, dist_patch], dim=0) # Stack along channel dim (C, H, W) -> (6, H, W)\n",
        "\n",
        "        return stacked_patches, score\n",
        "\n",
        "# Instantiate the ImagePairDataset for the training data (using patches and original ref images)\n",
        "patches_dir_path = os.path.join(PATCHES_PATH, \"copy\") # Assuming distorted patches are in 'copy' subfolder\n",
        "train_dataset = ImagePairDatasetPatches(metadata_file=os.path.join(PATCHES_PATH, 'train.json'), patch_dir=patches_dir_path, ref_img_original_dir=REF_PATH)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Implement the new TinyPatchRegressor model\n",
        "class TinyPatchRegressor(nn.Module):\n",
        "    def __init__(self, in_channels=6, use_groupnorm=True): # Input channels should be 6 for stacked RGB patches\n",
        "        super().__init__()\n",
        "        # 20x20-safe (padding keeps spatial size)\n",
        "        self.conv1 = nn.Conv2d(in_channels, 32, kernel_size=3, padding=1)\n",
        "        self.n1 = nn.GroupNorm(8, 32) if use_groupnorm else nn.BatchNorm2d(32)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32, 16, kernel_size=1)\n",
        "        self.n2 = nn.GroupNorm(4, 16) if use_groupnorm else nn.BatchNorm2d(16)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(16, 8, kernel_size=3, padding=1)  # keep some channels before GAP\n",
        "\n",
        "        self.gap = nn.AdaptiveAvgPool2d(1)  # -> [B,8,1,1]\n",
        "        self.dropout = nn.Dropout(0.10)\n",
        "        self.fc = nn.Linear(8, 1)           # linear head; no sigmoid\n",
        "\n",
        "        # Kaiming init\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
        "                if m.bias is not None: nn.init.zeros_(m.bias)\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_normal_(m.weight); nn.init.zeros_(m.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.n1(self.conv1(x)))\n",
        "        x = F.relu(self.n2(self.conv2(x)))\n",
        "        x = F.relu(self.conv3(x))                 # [B,8,20,20]\n",
        "        x = self.gap(x).view(x.size(0), 8)        # [B,8]\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc(x).squeeze(1)                 # [B]\n",
        "        return x\n",
        "\n",
        "model = TinyPatchRegressor(in_channels=6) # Initialize with 6 input channels\n",
        "\n",
        "\n",
        "print(\"Model architecture:\")\n",
        "print(model)\n",
        "\n",
        "\n",
        "# 3. Define the Mean Squared Error (MSE) loss function\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# 4. Define an optimizer (e.g., Adam) and specify the learning rate\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 5. Implement the training loop\n",
        "print(f\"\\nStarting training for {num_epochs} epochs...\")\n",
        "\n",
        "best_loss = float('inf')\n",
        "epochs_no_improve = 0\n",
        "\n",
        "# Initialize the gradient scaler for mixed precision training\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    model.train() # Set model to training mode\n",
        "    for i, data in enumerate(train_dataloader, 0):\n",
        "        # get the inputs; data is a list of [stacked_patches, scores]\n",
        "        inputs, scores = data\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Mixed precision training\n",
        "        with torch.cuda.amp.autocast():\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Calculate the MSE loss\n",
        "            # The TinyPatchRegressor outputs a single value (no sigmoid), so scores should match its shape [B]\n",
        "            scores = scores.float() # Ensure scores are float, shape [B]\n",
        "\n",
        "            loss = criterion(outputs, scores)\n",
        "\n",
        "        # Backward pass and optimize with scaler\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        # Accumulate running loss\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Print average loss for the epoch\n",
        "    epoch_loss = running_loss / len(train_dataloader)\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "    # Early stopping check (using training loss - ideally use validation loss)\n",
        "    if epoch_loss < best_loss - min_delta:\n",
        "        best_loss = epoch_loss\n",
        "        epochs_no_improve = 0\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        if epochs_no_improve >= patience:\n",
        "            print(f\"Early stopping triggered after {epoch + 1} epochs due to no improvement in training loss.\")\n",
        "            break # Stop training loop\n",
        "\n",
        "print(\"Finished Training\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1725804",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2b20237-4723-4ccb-c136-005f2a85b697"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting evaluation on the test set...\n",
            "Average Test Loss: 0.0120\n"
          ]
        }
      ],
      "source": [
        "# 1. Instantiate the ImagePairDataset for the testing data and create a DataLoader\n",
        "# Corrected metadata_file path to look directly in PATCHES_PATH\n",
        "patches_dir = os.path.join(PATCHES_PATH, \"copy\") # Assuming patches are in a 'copy' subfolder\n",
        "# Added the missing ref_img_original_dir argument\n",
        "test_dataset = ImagePairDatasetPatches(metadata_file=os.path.join(PATCHES_PATH, 'test.json'), patch_dir=patches_dir, ref_img_original_dir=REF_PATH)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False) # No need to shuffle test data\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "running_loss = 0.0\n",
        "total_samples = 0\n",
        "\n",
        "print(\"\\nStarting evaluation on the test set...\")\n",
        "\n",
        "# Disable gradient calculation for evaluation\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(test_dataloader, 0):\n",
        "        # get the inputs; data is a list of [stacked_patches, scores]\n",
        "        # Corrected data unpacking to match the dataset's output\n",
        "        inputs, scores = data\n",
        "\n",
        "        # No need to stack here, as the dataset already returns stacked patches\n",
        "        # inputs = torch.cat([ref_images, dist_images], dim=1) # Stack along the channel dimension (3 + 3 = 6 channels)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Calculate the MSE loss\n",
        "        # The TinyPatchRegressor outputs a single value (no sigmoid), so scores should match its shape [B]\n",
        "        scores = scores.float() # Ensure scores are float, shape [B]\n",
        "\n",
        "        loss = criterion(outputs, scores)\n",
        "\n",
        "        # Accumulate running loss and total samples\n",
        "        running_loss += loss.item() * inputs.size(0) # Multiply by batch size to get sum of losses\n",
        "        total_samples += inputs.size(0)\n",
        "\n",
        "# Calculate average loss for the test set\n",
        "average_test_loss = running_loss / total_samples\n",
        "print(f\"Average Test Loss: {average_test_loss:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}